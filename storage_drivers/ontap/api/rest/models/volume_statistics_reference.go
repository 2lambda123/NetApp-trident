// Code generated by go-swagger; DO NOT EDIT.

package models

// This file was generated by the swagger tool.
// Editing this file might prove futile when you re-run the swagger generate command

import (
	"context"
	"encoding/json"

	"github.com/go-openapi/errors"
	"github.com/go-openapi/strfmt"
	"github.com/go-openapi/swag"
	"github.com/go-openapi/validate"
)

// VolumeStatisticsReference These are raw performance numbers, such as IOPS latency and throughput. These numbers are aggregated across all nodes in the cluster and increase with the uptime of the cluster.
//
// swagger:model volume_statistics_reference
type VolumeStatisticsReference struct {

	// cloud
	Cloud *VolumeStatisticsReferenceCloud `json:"cloud,omitempty"`

	// iops raw
	IopsRaw *VolumeStatisticsReferenceIopsRaw `json:"iops_raw,omitempty"`

	// latency raw
	LatencyRaw *VolumeStatisticsReferenceLatencyRaw `json:"latency_raw,omitempty"`

	// Errors associated with the sample. For example, if the aggregation of data over multiple nodes fails, then any partial errors might return "ok" on success or "error" on an internal uncategorized failure. Whenever a sample collection is missed but done at a later time, it is back filled to the previous 15 second timestamp and tagged with "backfilled_data". "Inconsistent_ delta_time" is encountered when the time between two collections is not the same for all nodes. Therefore, the aggregated value might be over or under inflated. "Negative_delta" is returned when an expected monotonically increasing value has decreased in value. "Inconsistent_old_data" is returned when one or more nodes do not have the latest data.
	// Example: ok
	// Read Only: true
	// Enum: [ok error partial_no_data partial_no_uuid partial_no_response partial_other_error negative_delta backfilled_data inconsistent_delta_time inconsistent_old_data]
	Status string `json:"status,omitempty"`

	// throughput raw
	ThroughputRaw *VolumeStatisticsReferenceThroughputRaw `json:"throughput_raw,omitempty"`

	// The timestamp of the performance data.
	// Example: 2017-01-25 11:20:13
	// Read Only: true
	// Format: date-time
	Timestamp *strfmt.DateTime `json:"timestamp,omitempty"`
}

// Validate validates this volume statistics reference
func (m *VolumeStatisticsReference) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateCloud(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateIopsRaw(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateLatencyRaw(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateStatus(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateThroughputRaw(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateTimestamp(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *VolumeStatisticsReference) validateCloud(formats strfmt.Registry) error {
	if swag.IsZero(m.Cloud) { // not required
		return nil
	}

	if m.Cloud != nil {
		if err := m.Cloud.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("cloud")
			}
			return err
		}
	}

	return nil
}

func (m *VolumeStatisticsReference) validateIopsRaw(formats strfmt.Registry) error {
	if swag.IsZero(m.IopsRaw) { // not required
		return nil
	}

	if m.IopsRaw != nil {
		if err := m.IopsRaw.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("iops_raw")
			}
			return err
		}
	}

	return nil
}

func (m *VolumeStatisticsReference) validateLatencyRaw(formats strfmt.Registry) error {
	if swag.IsZero(m.LatencyRaw) { // not required
		return nil
	}

	if m.LatencyRaw != nil {
		if err := m.LatencyRaw.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("latency_raw")
			}
			return err
		}
	}

	return nil
}

var volumeStatisticsReferenceTypeStatusPropEnum []interface{}

func init() {
	var res []string
	if err := json.Unmarshal([]byte(`["ok","error","partial_no_data","partial_no_uuid","partial_no_response","partial_other_error","negative_delta","backfilled_data","inconsistent_delta_time","inconsistent_old_data"]`), &res); err != nil {
		panic(err)
	}
	for _, v := range res {
		volumeStatisticsReferenceTypeStatusPropEnum = append(volumeStatisticsReferenceTypeStatusPropEnum, v)
	}
}

const (

	// BEGIN RIPPY DEBUGGING
	// volume_statistics_reference
	// VolumeStatisticsReference
	// status
	// Status
	// ok
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceStatusOk captures enum value "ok"
	VolumeStatisticsReferenceStatusOk string = "ok"

	// BEGIN RIPPY DEBUGGING
	// volume_statistics_reference
	// VolumeStatisticsReference
	// status
	// Status
	// error
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceStatusError captures enum value "error"
	VolumeStatisticsReferenceStatusError string = "error"

	// BEGIN RIPPY DEBUGGING
	// volume_statistics_reference
	// VolumeStatisticsReference
	// status
	// Status
	// partial_no_data
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceStatusPartialNoData captures enum value "partial_no_data"
	VolumeStatisticsReferenceStatusPartialNoData string = "partial_no_data"

	// BEGIN RIPPY DEBUGGING
	// volume_statistics_reference
	// VolumeStatisticsReference
	// status
	// Status
	// partial_no_uuid
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceStatusPartialNoUUID captures enum value "partial_no_uuid"
	VolumeStatisticsReferenceStatusPartialNoUUID string = "partial_no_uuid"

	// BEGIN RIPPY DEBUGGING
	// volume_statistics_reference
	// VolumeStatisticsReference
	// status
	// Status
	// partial_no_response
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceStatusPartialNoResponse captures enum value "partial_no_response"
	VolumeStatisticsReferenceStatusPartialNoResponse string = "partial_no_response"

	// BEGIN RIPPY DEBUGGING
	// volume_statistics_reference
	// VolumeStatisticsReference
	// status
	// Status
	// partial_other_error
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceStatusPartialOtherError captures enum value "partial_other_error"
	VolumeStatisticsReferenceStatusPartialOtherError string = "partial_other_error"

	// BEGIN RIPPY DEBUGGING
	// volume_statistics_reference
	// VolumeStatisticsReference
	// status
	// Status
	// negative_delta
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceStatusNegativeDelta captures enum value "negative_delta"
	VolumeStatisticsReferenceStatusNegativeDelta string = "negative_delta"

	// BEGIN RIPPY DEBUGGING
	// volume_statistics_reference
	// VolumeStatisticsReference
	// status
	// Status
	// backfilled_data
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceStatusBackfilledData captures enum value "backfilled_data"
	VolumeStatisticsReferenceStatusBackfilledData string = "backfilled_data"

	// BEGIN RIPPY DEBUGGING
	// volume_statistics_reference
	// VolumeStatisticsReference
	// status
	// Status
	// inconsistent_delta_time
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceStatusInconsistentDeltaTime captures enum value "inconsistent_delta_time"
	VolumeStatisticsReferenceStatusInconsistentDeltaTime string = "inconsistent_delta_time"

	// BEGIN RIPPY DEBUGGING
	// volume_statistics_reference
	// VolumeStatisticsReference
	// status
	// Status
	// inconsistent_old_data
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceStatusInconsistentOldData captures enum value "inconsistent_old_data"
	VolumeStatisticsReferenceStatusInconsistentOldData string = "inconsistent_old_data"
)

// prop value enum
func (m *VolumeStatisticsReference) validateStatusEnum(path, location string, value string) error {
	if err := validate.EnumCase(path, location, value, volumeStatisticsReferenceTypeStatusPropEnum, true); err != nil {
		return err
	}
	return nil
}

func (m *VolumeStatisticsReference) validateStatus(formats strfmt.Registry) error {
	if swag.IsZero(m.Status) { // not required
		return nil
	}

	// value enum
	if err := m.validateStatusEnum("status", "body", m.Status); err != nil {
		return err
	}

	return nil
}

func (m *VolumeStatisticsReference) validateThroughputRaw(formats strfmt.Registry) error {
	if swag.IsZero(m.ThroughputRaw) { // not required
		return nil
	}

	if m.ThroughputRaw != nil {
		if err := m.ThroughputRaw.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("throughput_raw")
			}
			return err
		}
	}

	return nil
}

func (m *VolumeStatisticsReference) validateTimestamp(formats strfmt.Registry) error {
	if swag.IsZero(m.Timestamp) { // not required
		return nil
	}

	if err := validate.FormatOf("timestamp", "body", "date-time", m.Timestamp.String(), formats); err != nil {
		return err
	}

	return nil
}

// ContextValidate validate this volume statistics reference based on the context it is used
func (m *VolumeStatisticsReference) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateCloud(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateIopsRaw(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateLatencyRaw(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateStatus(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateThroughputRaw(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateTimestamp(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *VolumeStatisticsReference) contextValidateCloud(ctx context.Context, formats strfmt.Registry) error {

	if m.Cloud != nil {
		if err := m.Cloud.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("cloud")
			}
			return err
		}
	}

	return nil
}

func (m *VolumeStatisticsReference) contextValidateIopsRaw(ctx context.Context, formats strfmt.Registry) error {

	if m.IopsRaw != nil {
		if err := m.IopsRaw.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("iops_raw")
			}
			return err
		}
	}

	return nil
}

func (m *VolumeStatisticsReference) contextValidateLatencyRaw(ctx context.Context, formats strfmt.Registry) error {

	if m.LatencyRaw != nil {
		if err := m.LatencyRaw.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("latency_raw")
			}
			return err
		}
	}

	return nil
}

func (m *VolumeStatisticsReference) contextValidateStatus(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "status", "body", string(m.Status)); err != nil {
		return err
	}

	return nil
}

func (m *VolumeStatisticsReference) contextValidateThroughputRaw(ctx context.Context, formats strfmt.Registry) error {

	if m.ThroughputRaw != nil {
		if err := m.ThroughputRaw.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("throughput_raw")
			}
			return err
		}
	}

	return nil
}

func (m *VolumeStatisticsReference) contextValidateTimestamp(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "timestamp", "body", m.Timestamp); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *VolumeStatisticsReference) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *VolumeStatisticsReference) UnmarshalBinary(b []byte) error {
	var res VolumeStatisticsReference
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// VolumeStatisticsReferenceCloud These are raw performance numbers (IOPS and latency) for the cloud store. These numbers are aggregated across all nodes in the cluster and increase with the uptime of the cluster. These numbers are relevant only for volumes hosted on FabricPools.
//
// swagger:model VolumeStatisticsReferenceCloud
type VolumeStatisticsReferenceCloud struct {

	// iops raw
	IopsRaw *VolumeStatisticsReferenceCloudIopsRaw `json:"iops_raw,omitempty"`

	// latency raw
	LatencyRaw *VolumeStatisticsReferenceCloudLatencyRaw `json:"latency_raw,omitempty"`

	// Errors associated with the sample. For example, if the aggregation of data over multiple nodes fails, then any partial errors might return "ok" on success or "error" on an internal uncategorized failure. Whenever a sample collection is missed but done at a later time, it is back filled to the previous 15 second timestamp and tagged with "backfilled_data". "Inconsistent_ delta_time" is encountered when the time between two collections is not the same for all nodes. Therefore, the aggregated value might be over or under inflated. "Negative_delta" is returned when an expected monotonically increasing value has decreased in value. "Inconsistent_old_data" is returned when one or more nodes do not have the latest data.
	// Example: ok
	// Read Only: true
	// Enum: [ok error partial_no_data partial_no_uuid partial_no_response partial_other_error negative_delta backfilled_data inconsistent_delta_time inconsistent_old_data]
	Status string `json:"status,omitempty"`

	// The timestamp of the performance data.
	// Example: 2017-01-25 11:20:13
	// Read Only: true
	// Format: date-time
	Timestamp *strfmt.DateTime `json:"timestamp,omitempty"`
}

// Validate validates this volume statistics reference cloud
func (m *VolumeStatisticsReferenceCloud) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateIopsRaw(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateLatencyRaw(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateStatus(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateTimestamp(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *VolumeStatisticsReferenceCloud) validateIopsRaw(formats strfmt.Registry) error {
	if swag.IsZero(m.IopsRaw) { // not required
		return nil
	}

	if m.IopsRaw != nil {
		if err := m.IopsRaw.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("cloud" + "." + "iops_raw")
			}
			return err
		}
	}

	return nil
}

func (m *VolumeStatisticsReferenceCloud) validateLatencyRaw(formats strfmt.Registry) error {
	if swag.IsZero(m.LatencyRaw) { // not required
		return nil
	}

	if m.LatencyRaw != nil {
		if err := m.LatencyRaw.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("cloud" + "." + "latency_raw")
			}
			return err
		}
	}

	return nil
}

var volumeStatisticsReferenceCloudTypeStatusPropEnum []interface{}

func init() {
	var res []string
	if err := json.Unmarshal([]byte(`["ok","error","partial_no_data","partial_no_uuid","partial_no_response","partial_other_error","negative_delta","backfilled_data","inconsistent_delta_time","inconsistent_old_data"]`), &res); err != nil {
		panic(err)
	}
	for _, v := range res {
		volumeStatisticsReferenceCloudTypeStatusPropEnum = append(volumeStatisticsReferenceCloudTypeStatusPropEnum, v)
	}
}

const (

	// BEGIN RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloud
	// VolumeStatisticsReferenceCloud
	// status
	// Status
	// ok
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloudStatusOk captures enum value "ok"
	VolumeStatisticsReferenceCloudStatusOk string = "ok"

	// BEGIN RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloud
	// VolumeStatisticsReferenceCloud
	// status
	// Status
	// error
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloudStatusError captures enum value "error"
	VolumeStatisticsReferenceCloudStatusError string = "error"

	// BEGIN RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloud
	// VolumeStatisticsReferenceCloud
	// status
	// Status
	// partial_no_data
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloudStatusPartialNoData captures enum value "partial_no_data"
	VolumeStatisticsReferenceCloudStatusPartialNoData string = "partial_no_data"

	// BEGIN RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloud
	// VolumeStatisticsReferenceCloud
	// status
	// Status
	// partial_no_uuid
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloudStatusPartialNoUUID captures enum value "partial_no_uuid"
	VolumeStatisticsReferenceCloudStatusPartialNoUUID string = "partial_no_uuid"

	// BEGIN RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloud
	// VolumeStatisticsReferenceCloud
	// status
	// Status
	// partial_no_response
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloudStatusPartialNoResponse captures enum value "partial_no_response"
	VolumeStatisticsReferenceCloudStatusPartialNoResponse string = "partial_no_response"

	// BEGIN RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloud
	// VolumeStatisticsReferenceCloud
	// status
	// Status
	// partial_other_error
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloudStatusPartialOtherError captures enum value "partial_other_error"
	VolumeStatisticsReferenceCloudStatusPartialOtherError string = "partial_other_error"

	// BEGIN RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloud
	// VolumeStatisticsReferenceCloud
	// status
	// Status
	// negative_delta
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloudStatusNegativeDelta captures enum value "negative_delta"
	VolumeStatisticsReferenceCloudStatusNegativeDelta string = "negative_delta"

	// BEGIN RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloud
	// VolumeStatisticsReferenceCloud
	// status
	// Status
	// backfilled_data
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloudStatusBackfilledData captures enum value "backfilled_data"
	VolumeStatisticsReferenceCloudStatusBackfilledData string = "backfilled_data"

	// BEGIN RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloud
	// VolumeStatisticsReferenceCloud
	// status
	// Status
	// inconsistent_delta_time
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloudStatusInconsistentDeltaTime captures enum value "inconsistent_delta_time"
	VolumeStatisticsReferenceCloudStatusInconsistentDeltaTime string = "inconsistent_delta_time"

	// BEGIN RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloud
	// VolumeStatisticsReferenceCloud
	// status
	// Status
	// inconsistent_old_data
	// END RIPPY DEBUGGING
	// VolumeStatisticsReferenceCloudStatusInconsistentOldData captures enum value "inconsistent_old_data"
	VolumeStatisticsReferenceCloudStatusInconsistentOldData string = "inconsistent_old_data"
)

// prop value enum
func (m *VolumeStatisticsReferenceCloud) validateStatusEnum(path, location string, value string) error {
	if err := validate.EnumCase(path, location, value, volumeStatisticsReferenceCloudTypeStatusPropEnum, true); err != nil {
		return err
	}
	return nil
}

func (m *VolumeStatisticsReferenceCloud) validateStatus(formats strfmt.Registry) error {
	if swag.IsZero(m.Status) { // not required
		return nil
	}

	// value enum
	if err := m.validateStatusEnum("cloud"+"."+"status", "body", m.Status); err != nil {
		return err
	}

	return nil
}

func (m *VolumeStatisticsReferenceCloud) validateTimestamp(formats strfmt.Registry) error {
	if swag.IsZero(m.Timestamp) { // not required
		return nil
	}

	if err := validate.FormatOf("cloud"+"."+"timestamp", "body", "date-time", m.Timestamp.String(), formats); err != nil {
		return err
	}

	return nil
}

// ContextValidate validate this volume statistics reference cloud based on the context it is used
func (m *VolumeStatisticsReferenceCloud) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateIopsRaw(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateLatencyRaw(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateStatus(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateTimestamp(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *VolumeStatisticsReferenceCloud) contextValidateIopsRaw(ctx context.Context, formats strfmt.Registry) error {

	if m.IopsRaw != nil {
		if err := m.IopsRaw.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("cloud" + "." + "iops_raw")
			}
			return err
		}
	}

	return nil
}

func (m *VolumeStatisticsReferenceCloud) contextValidateLatencyRaw(ctx context.Context, formats strfmt.Registry) error {

	if m.LatencyRaw != nil {
		if err := m.LatencyRaw.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("cloud" + "." + "latency_raw")
			}
			return err
		}
	}

	return nil
}

func (m *VolumeStatisticsReferenceCloud) contextValidateStatus(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "cloud"+"."+"status", "body", string(m.Status)); err != nil {
		return err
	}

	return nil
}

func (m *VolumeStatisticsReferenceCloud) contextValidateTimestamp(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "cloud"+"."+"timestamp", "body", m.Timestamp); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *VolumeStatisticsReferenceCloud) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *VolumeStatisticsReferenceCloud) UnmarshalBinary(b []byte) error {
	var res VolumeStatisticsReferenceCloud
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// VolumeStatisticsReferenceCloudIopsRaw The number of I/O operations observed at the storage object. This can be used along with delta time to calculate the rate of I/O operations per unit of time.
//
// swagger:model VolumeStatisticsReferenceCloudIopsRaw
type VolumeStatisticsReferenceCloudIopsRaw struct {

	// Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.
	Other int64 `json:"other,omitempty"`

	// Performance metric for read I/O operations.
	// Example: 200
	Read int64 `json:"read,omitempty"`

	// Performance metric aggregated over all types of I/O operations.
	// Example: 1000
	Total int64 `json:"total,omitempty"`

	// Peformance metric for write I/O operations.
	// Example: 100
	Write int64 `json:"write,omitempty"`
}

// Validate validates this volume statistics reference cloud iops raw
func (m *VolumeStatisticsReferenceCloudIopsRaw) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this volume statistics reference cloud iops raw based on the context it is used
func (m *VolumeStatisticsReferenceCloudIopsRaw) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

// MarshalBinary interface implementation
func (m *VolumeStatisticsReferenceCloudIopsRaw) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *VolumeStatisticsReferenceCloudIopsRaw) UnmarshalBinary(b []byte) error {
	var res VolumeStatisticsReferenceCloudIopsRaw
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// VolumeStatisticsReferenceCloudLatencyRaw The raw latency in microseconds observed at the storage object. This can be divided by the raw IOPS value to calculate the average latency per I/O operation.
//
// swagger:model VolumeStatisticsReferenceCloudLatencyRaw
type VolumeStatisticsReferenceCloudLatencyRaw struct {

	// Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.
	Other int64 `json:"other,omitempty"`

	// Performance metric for read I/O operations.
	// Example: 200
	Read int64 `json:"read,omitempty"`

	// Performance metric aggregated over all types of I/O operations.
	// Example: 1000
	Total int64 `json:"total,omitempty"`

	// Peformance metric for write I/O operations.
	// Example: 100
	Write int64 `json:"write,omitempty"`
}

// Validate validates this volume statistics reference cloud latency raw
func (m *VolumeStatisticsReferenceCloudLatencyRaw) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this volume statistics reference cloud latency raw based on the context it is used
func (m *VolumeStatisticsReferenceCloudLatencyRaw) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

// MarshalBinary interface implementation
func (m *VolumeStatisticsReferenceCloudLatencyRaw) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *VolumeStatisticsReferenceCloudLatencyRaw) UnmarshalBinary(b []byte) error {
	var res VolumeStatisticsReferenceCloudLatencyRaw
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// VolumeStatisticsReferenceIopsRaw The number of I/O operations observed at the storage object. This can be used along with delta time to calculate the rate of I/O operations per unit of time.
//
// swagger:model VolumeStatisticsReferenceIopsRaw
type VolumeStatisticsReferenceIopsRaw struct {

	// Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.
	Other int64 `json:"other,omitempty"`

	// Performance metric for read I/O operations.
	// Example: 200
	Read int64 `json:"read,omitempty"`

	// Performance metric aggregated over all types of I/O operations.
	// Example: 1000
	Total int64 `json:"total,omitempty"`

	// Peformance metric for write I/O operations.
	// Example: 100
	Write int64 `json:"write,omitempty"`
}

// Validate validates this volume statistics reference iops raw
func (m *VolumeStatisticsReferenceIopsRaw) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this volume statistics reference iops raw based on the context it is used
func (m *VolumeStatisticsReferenceIopsRaw) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

// MarshalBinary interface implementation
func (m *VolumeStatisticsReferenceIopsRaw) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *VolumeStatisticsReferenceIopsRaw) UnmarshalBinary(b []byte) error {
	var res VolumeStatisticsReferenceIopsRaw
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// VolumeStatisticsReferenceLatencyRaw The raw latency in microseconds observed at the storage object. This can be divided by the raw IOPS value to calculate the average latency per I/O operation.
//
// swagger:model VolumeStatisticsReferenceLatencyRaw
type VolumeStatisticsReferenceLatencyRaw struct {

	// Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.
	Other int64 `json:"other,omitempty"`

	// Performance metric for read I/O operations.
	// Example: 200
	Read int64 `json:"read,omitempty"`

	// Performance metric aggregated over all types of I/O operations.
	// Example: 1000
	Total int64 `json:"total,omitempty"`

	// Peformance metric for write I/O operations.
	// Example: 100
	Write int64 `json:"write,omitempty"`
}

// Validate validates this volume statistics reference latency raw
func (m *VolumeStatisticsReferenceLatencyRaw) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this volume statistics reference latency raw based on the context it is used
func (m *VolumeStatisticsReferenceLatencyRaw) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

// MarshalBinary interface implementation
func (m *VolumeStatisticsReferenceLatencyRaw) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *VolumeStatisticsReferenceLatencyRaw) UnmarshalBinary(b []byte) error {
	var res VolumeStatisticsReferenceLatencyRaw
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// VolumeStatisticsReferenceThroughputRaw Throughput bytes observed at the storage object. This can be used along with delta time to calculate the rate of throughput bytes per unit of time.
//
// swagger:model VolumeStatisticsReferenceThroughputRaw
type VolumeStatisticsReferenceThroughputRaw struct {

	// Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.
	Other int64 `json:"other,omitempty"`

	// Performance metric for read I/O operations.
	// Example: 200
	Read int64 `json:"read,omitempty"`

	// Performance metric aggregated over all types of I/O operations.
	// Example: 1000
	Total int64 `json:"total,omitempty"`

	// Peformance metric for write I/O operations.
	// Example: 100
	Write int64 `json:"write,omitempty"`
}

// Validate validates this volume statistics reference throughput raw
func (m *VolumeStatisticsReferenceThroughputRaw) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this volume statistics reference throughput raw based on the context it is used
func (m *VolumeStatisticsReferenceThroughputRaw) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

// MarshalBinary interface implementation
func (m *VolumeStatisticsReferenceThroughputRaw) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *VolumeStatisticsReferenceThroughputRaw) UnmarshalBinary(b []byte) error {
	var res VolumeStatisticsReferenceThroughputRaw
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// HELLO RIPPY
