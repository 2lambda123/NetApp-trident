// Code generated by go-swagger; DO NOT EDIT.

package models

// This file was generated by the swagger tool.
// Editing this file might prove futile when you re-run the swagger generate command

import (
	"context"
	"encoding/json"
	"strconv"

	"github.com/go-openapi/errors"
	"github.com/go-openapi/strfmt"
	"github.com/go-openapi/swag"
	"github.com/go-openapi/validate"
)

// Aggregate aggregate
//
// swagger:model aggregate
type Aggregate struct {

	// links
	Links *AggregateLinks `json:"_links,omitempty"`

	// block storage
	BlockStorage *AggregateBlockStorage `json:"block_storage,omitempty"`

	// cloud storage
	CloudStorage *AggregateCloudStorage `json:"cloud_storage,omitempty"`

	// Timestamp of aggregate creation
	// Example: 2018-01-01 16:00:00
	// Read Only: true
	CreateTime string `json:"create_time,omitempty"`

	// data encryption
	DataEncryption *AggregateDataEncryption `json:"data_encryption,omitempty"`

	// dr home node
	DrHomeNode *AggregateDrHomeNode `json:"dr_home_node,omitempty"`

	// home node
	HomeNode *AggregateHomeNode `json:"home_node,omitempty"`

	// metric
	Metric *AggregateMetric `json:"metric,omitempty"`

	// Aggregate name
	// Example: node1_aggr_1
	Name string `json:"name,omitempty"`

	// node
	Node *AggregateNode `json:"node,omitempty"`

	// SnapLock type
	// Enum: [non_snaplock compliance enterprise]
	SnaplockType string `json:"snaplock_type,omitempty"`

	// space
	Space *AggregateSpace `json:"space,omitempty"`

	// Operational state of the aggregate
	// Read Only: true
	// Enum: [online onlining offline offlining relocating unmounted restricted inconsistent failed unknown]
	State string `json:"state,omitempty"`

	// statistics
	Statistics *AggregateStatistics `json:"statistics,omitempty"`

	// Aggregate UUID
	// Read Only: true
	UUID string `json:"uuid,omitempty"`
}

// Validate validates this aggregate
func (m *Aggregate) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateLinks(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateBlockStorage(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateCloudStorage(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateDataEncryption(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateDrHomeNode(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateHomeNode(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateMetric(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateNode(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateSnaplockType(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateSpace(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateState(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateStatistics(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *Aggregate) validateLinks(formats strfmt.Registry) error {
	if swag.IsZero(m.Links) { // not required
		return nil
	}

	if m.Links != nil {
		if err := m.Links.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("_links")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) validateBlockStorage(formats strfmt.Registry) error {
	if swag.IsZero(m.BlockStorage) { // not required
		return nil
	}

	if m.BlockStorage != nil {
		if err := m.BlockStorage.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("block_storage")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) validateCloudStorage(formats strfmt.Registry) error {
	if swag.IsZero(m.CloudStorage) { // not required
		return nil
	}

	if m.CloudStorage != nil {
		if err := m.CloudStorage.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("cloud_storage")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) validateDataEncryption(formats strfmt.Registry) error {
	if swag.IsZero(m.DataEncryption) { // not required
		return nil
	}

	if m.DataEncryption != nil {
		if err := m.DataEncryption.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("data_encryption")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) validateDrHomeNode(formats strfmt.Registry) error {
	if swag.IsZero(m.DrHomeNode) { // not required
		return nil
	}

	if m.DrHomeNode != nil {
		if err := m.DrHomeNode.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("dr_home_node")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) validateHomeNode(formats strfmt.Registry) error {
	if swag.IsZero(m.HomeNode) { // not required
		return nil
	}

	if m.HomeNode != nil {
		if err := m.HomeNode.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("home_node")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) validateMetric(formats strfmt.Registry) error {
	if swag.IsZero(m.Metric) { // not required
		return nil
	}

	if m.Metric != nil {
		if err := m.Metric.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("metric")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) validateNode(formats strfmt.Registry) error {
	if swag.IsZero(m.Node) { // not required
		return nil
	}

	if m.Node != nil {
		if err := m.Node.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("node")
			}
			return err
		}
	}

	return nil
}

var aggregateTypeSnaplockTypePropEnum []interface{}

func init() {
	var res []string
	if err := json.Unmarshal([]byte(`["non_snaplock","compliance","enterprise"]`), &res); err != nil {
		panic(err)
	}
	for _, v := range res {
		aggregateTypeSnaplockTypePropEnum = append(aggregateTypeSnaplockTypePropEnum, v)
	}
}

const (

	// BEGIN RIPPY DEBUGGING
	// aggregate
	// Aggregate
	// snaplock_type
	// SnaplockType
	// non_snaplock
	// END RIPPY DEBUGGING
	// AggregateSnaplockTypeNonSnaplock captures enum value "non_snaplock"
	AggregateSnaplockTypeNonSnaplock string = "non_snaplock"

	// BEGIN RIPPY DEBUGGING
	// aggregate
	// Aggregate
	// snaplock_type
	// SnaplockType
	// compliance
	// END RIPPY DEBUGGING
	// AggregateSnaplockTypeCompliance captures enum value "compliance"
	AggregateSnaplockTypeCompliance string = "compliance"

	// BEGIN RIPPY DEBUGGING
	// aggregate
	// Aggregate
	// snaplock_type
	// SnaplockType
	// enterprise
	// END RIPPY DEBUGGING
	// AggregateSnaplockTypeEnterprise captures enum value "enterprise"
	AggregateSnaplockTypeEnterprise string = "enterprise"
)

// prop value enum
func (m *Aggregate) validateSnaplockTypeEnum(path, location string, value string) error {
	if err := validate.EnumCase(path, location, value, aggregateTypeSnaplockTypePropEnum, true); err != nil {
		return err
	}
	return nil
}

func (m *Aggregate) validateSnaplockType(formats strfmt.Registry) error {
	if swag.IsZero(m.SnaplockType) { // not required
		return nil
	}

	// value enum
	if err := m.validateSnaplockTypeEnum("snaplock_type", "body", m.SnaplockType); err != nil {
		return err
	}

	return nil
}

func (m *Aggregate) validateSpace(formats strfmt.Registry) error {
	if swag.IsZero(m.Space) { // not required
		return nil
	}

	if m.Space != nil {
		if err := m.Space.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("space")
			}
			return err
		}
	}

	return nil
}

var aggregateTypeStatePropEnum []interface{}

func init() {
	var res []string
	if err := json.Unmarshal([]byte(`["online","onlining","offline","offlining","relocating","unmounted","restricted","inconsistent","failed","unknown"]`), &res); err != nil {
		panic(err)
	}
	for _, v := range res {
		aggregateTypeStatePropEnum = append(aggregateTypeStatePropEnum, v)
	}
}

const (

	// BEGIN RIPPY DEBUGGING
	// aggregate
	// Aggregate
	// state
	// State
	// online
	// END RIPPY DEBUGGING
	// AggregateStateOnline captures enum value "online"
	AggregateStateOnline string = "online"

	// BEGIN RIPPY DEBUGGING
	// aggregate
	// Aggregate
	// state
	// State
	// onlining
	// END RIPPY DEBUGGING
	// AggregateStateOnlining captures enum value "onlining"
	AggregateStateOnlining string = "onlining"

	// BEGIN RIPPY DEBUGGING
	// aggregate
	// Aggregate
	// state
	// State
	// offline
	// END RIPPY DEBUGGING
	// AggregateStateOffline captures enum value "offline"
	AggregateStateOffline string = "offline"

	// BEGIN RIPPY DEBUGGING
	// aggregate
	// Aggregate
	// state
	// State
	// offlining
	// END RIPPY DEBUGGING
	// AggregateStateOfflining captures enum value "offlining"
	AggregateStateOfflining string = "offlining"

	// BEGIN RIPPY DEBUGGING
	// aggregate
	// Aggregate
	// state
	// State
	// relocating
	// END RIPPY DEBUGGING
	// AggregateStateRelocating captures enum value "relocating"
	AggregateStateRelocating string = "relocating"

	// BEGIN RIPPY DEBUGGING
	// aggregate
	// Aggregate
	// state
	// State
	// unmounted
	// END RIPPY DEBUGGING
	// AggregateStateUnmounted captures enum value "unmounted"
	AggregateStateUnmounted string = "unmounted"

	// BEGIN RIPPY DEBUGGING
	// aggregate
	// Aggregate
	// state
	// State
	// restricted
	// END RIPPY DEBUGGING
	// AggregateStateRestricted captures enum value "restricted"
	AggregateStateRestricted string = "restricted"

	// BEGIN RIPPY DEBUGGING
	// aggregate
	// Aggregate
	// state
	// State
	// inconsistent
	// END RIPPY DEBUGGING
	// AggregateStateInconsistent captures enum value "inconsistent"
	AggregateStateInconsistent string = "inconsistent"

	// BEGIN RIPPY DEBUGGING
	// aggregate
	// Aggregate
	// state
	// State
	// failed
	// END RIPPY DEBUGGING
	// AggregateStateFailed captures enum value "failed"
	AggregateStateFailed string = "failed"

	// BEGIN RIPPY DEBUGGING
	// aggregate
	// Aggregate
	// state
	// State
	// unknown
	// END RIPPY DEBUGGING
	// AggregateStateUnknown captures enum value "unknown"
	AggregateStateUnknown string = "unknown"
)

// prop value enum
func (m *Aggregate) validateStateEnum(path, location string, value string) error {
	if err := validate.EnumCase(path, location, value, aggregateTypeStatePropEnum, true); err != nil {
		return err
	}
	return nil
}

func (m *Aggregate) validateState(formats strfmt.Registry) error {
	if swag.IsZero(m.State) { // not required
		return nil
	}

	// value enum
	if err := m.validateStateEnum("state", "body", m.State); err != nil {
		return err
	}

	return nil
}

func (m *Aggregate) validateStatistics(formats strfmt.Registry) error {
	if swag.IsZero(m.Statistics) { // not required
		return nil
	}

	if m.Statistics != nil {
		if err := m.Statistics.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("statistics")
			}
			return err
		}
	}

	return nil
}

// ContextValidate validate this aggregate based on the context it is used
func (m *Aggregate) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateLinks(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateBlockStorage(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateCloudStorage(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateCreateTime(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateDataEncryption(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateDrHomeNode(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateHomeNode(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateMetric(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateNode(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateSpace(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateState(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateStatistics(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateUUID(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *Aggregate) contextValidateLinks(ctx context.Context, formats strfmt.Registry) error {

	if m.Links != nil {
		if err := m.Links.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("_links")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) contextValidateBlockStorage(ctx context.Context, formats strfmt.Registry) error {

	if m.BlockStorage != nil {
		if err := m.BlockStorage.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("block_storage")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) contextValidateCloudStorage(ctx context.Context, formats strfmt.Registry) error {

	if m.CloudStorage != nil {
		if err := m.CloudStorage.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("cloud_storage")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) contextValidateCreateTime(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "create_time", "body", string(m.CreateTime)); err != nil {
		return err
	}

	return nil
}

func (m *Aggregate) contextValidateDataEncryption(ctx context.Context, formats strfmt.Registry) error {

	if m.DataEncryption != nil {
		if err := m.DataEncryption.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("data_encryption")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) contextValidateDrHomeNode(ctx context.Context, formats strfmt.Registry) error {

	if m.DrHomeNode != nil {
		if err := m.DrHomeNode.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("dr_home_node")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) contextValidateHomeNode(ctx context.Context, formats strfmt.Registry) error {

	if m.HomeNode != nil {
		if err := m.HomeNode.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("home_node")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) contextValidateMetric(ctx context.Context, formats strfmt.Registry) error {

	if m.Metric != nil {
		if err := m.Metric.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("metric")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) contextValidateNode(ctx context.Context, formats strfmt.Registry) error {

	if m.Node != nil {
		if err := m.Node.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("node")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) contextValidateSpace(ctx context.Context, formats strfmt.Registry) error {

	if m.Space != nil {
		if err := m.Space.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("space")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) contextValidateState(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "state", "body", string(m.State)); err != nil {
		return err
	}

	return nil
}

func (m *Aggregate) contextValidateStatistics(ctx context.Context, formats strfmt.Registry) error {

	if m.Statistics != nil {
		if err := m.Statistics.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("statistics")
			}
			return err
		}
	}

	return nil
}

func (m *Aggregate) contextValidateUUID(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "uuid", "body", string(m.UUID)); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *Aggregate) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *Aggregate) UnmarshalBinary(b []byte) error {
	var res Aggregate
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateBlockStorage Configuration information for the locally attached portion of the aggregate. When a cloud store is also used by this aggregate, this is referred to as the performance tier.
//
// swagger:model AggregateBlockStorage
type AggregateBlockStorage struct {

	// hybrid cache
	HybridCache *AggregateBlockStorageHybridCache `json:"hybrid_cache,omitempty"`

	// mirror
	Mirror *AggregateBlockStorageMirror `json:"mirror,omitempty"`

	// Plex reference for each plex in the aggregate.
	// Read Only: true
	Plexes []*PlexReference `json:"plexes,omitempty"`

	// primary
	Primary *AggregateBlockStoragePrimary `json:"primary,omitempty"`
}

// Validate validates this aggregate block storage
func (m *AggregateBlockStorage) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateHybridCache(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateMirror(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validatePlexes(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validatePrimary(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateBlockStorage) validateHybridCache(formats strfmt.Registry) error {
	if swag.IsZero(m.HybridCache) { // not required
		return nil
	}

	if m.HybridCache != nil {
		if err := m.HybridCache.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("block_storage" + "." + "hybrid_cache")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateBlockStorage) validateMirror(formats strfmt.Registry) error {
	if swag.IsZero(m.Mirror) { // not required
		return nil
	}

	if m.Mirror != nil {
		if err := m.Mirror.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("block_storage" + "." + "mirror")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateBlockStorage) validatePlexes(formats strfmt.Registry) error {
	if swag.IsZero(m.Plexes) { // not required
		return nil
	}

	for i := 0; i < len(m.Plexes); i++ {
		if swag.IsZero(m.Plexes[i]) { // not required
			continue
		}

		if m.Plexes[i] != nil {
			if err := m.Plexes[i].Validate(formats); err != nil {
				if ve, ok := err.(*errors.Validation); ok {
					return ve.ValidateName("block_storage" + "." + "plexes" + "." + strconv.Itoa(i))
				}
				return err
			}
		}

	}

	return nil
}

func (m *AggregateBlockStorage) validatePrimary(formats strfmt.Registry) error {
	if swag.IsZero(m.Primary) { // not required
		return nil
	}

	if m.Primary != nil {
		if err := m.Primary.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("block_storage" + "." + "primary")
			}
			return err
		}
	}

	return nil
}

// ContextValidate validate this aggregate block storage based on the context it is used
func (m *AggregateBlockStorage) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateHybridCache(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateMirror(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidatePlexes(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidatePrimary(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateBlockStorage) contextValidateHybridCache(ctx context.Context, formats strfmt.Registry) error {

	if m.HybridCache != nil {
		if err := m.HybridCache.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("block_storage" + "." + "hybrid_cache")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateBlockStorage) contextValidateMirror(ctx context.Context, formats strfmt.Registry) error {

	if m.Mirror != nil {
		if err := m.Mirror.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("block_storage" + "." + "mirror")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateBlockStorage) contextValidatePlexes(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "block_storage"+"."+"plexes", "body", []*PlexReference(m.Plexes)); err != nil {
		return err
	}

	for i := 0; i < len(m.Plexes); i++ {

		if m.Plexes[i] != nil {
			if err := m.Plexes[i].ContextValidate(ctx, formats); err != nil {
				if ve, ok := err.(*errors.Validation); ok {
					return ve.ValidateName("block_storage" + "." + "plexes" + "." + strconv.Itoa(i))
				}
				return err
			}
		}

	}

	return nil
}

func (m *AggregateBlockStorage) contextValidatePrimary(ctx context.Context, formats strfmt.Registry) error {

	if m.Primary != nil {
		if err := m.Primary.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("block_storage" + "." + "primary")
			}
			return err
		}
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateBlockStorage) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateBlockStorage) UnmarshalBinary(b []byte) error {
	var res AggregateBlockStorage
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateBlockStorageHybridCache Contains the configuration for the hybrid cache. The hybrid cache is made up of either whole SSDs or storage pool SSDs.
//
// swagger:model AggregateBlockStorageHybridCache
type AggregateBlockStorageHybridCache struct {

	// Number of disks used in the cache tier of the aggregate. Only provided when hybrid_cache.enabled is 'true'.
	// Example: 6
	// Read Only: true
	DiskCount int64 `json:"disk_count,omitempty"`

	// Aggregate uses HDDs with SSDs as a cache
	// Read Only: true
	Enabled *bool `json:"enabled,omitempty"`

	// RAID type for SSD cache of the aggregate. Only provided when hybrid_cache.enabled is 'true'.
	// Read Only: true
	// Enum: [raid_dp raid_tec raid4]
	RaidType string `json:"raid_type,omitempty"`

	// Total usable space in bytes of SSD cache. Only provided when hybrid_cache.enabled is 'true'.
	// Example: 1612709888
	// Read Only: true
	Size int64 `json:"size,omitempty"`

	// Space used in bytes of SSD cache. Only provided when hybrid_cache.enabled is 'true'.
	// Example: 26501122
	// Read Only: true
	Used int64 `json:"used,omitempty"`
}

// Validate validates this aggregate block storage hybrid cache
func (m *AggregateBlockStorageHybridCache) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateRaidType(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

var aggregateBlockStorageHybridCacheTypeRaidTypePropEnum []interface{}

func init() {
	var res []string
	if err := json.Unmarshal([]byte(`["raid_dp","raid_tec","raid4"]`), &res); err != nil {
		panic(err)
	}
	for _, v := range res {
		aggregateBlockStorageHybridCacheTypeRaidTypePropEnum = append(aggregateBlockStorageHybridCacheTypeRaidTypePropEnum, v)
	}
}

const (

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStorageHybridCache
	// AggregateBlockStorageHybridCache
	// raid_type
	// RaidType
	// raid_dp
	// END RIPPY DEBUGGING
	// AggregateBlockStorageHybridCacheRaidTypeRaidDp captures enum value "raid_dp"
	AggregateBlockStorageHybridCacheRaidTypeRaidDp string = "raid_dp"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStorageHybridCache
	// AggregateBlockStorageHybridCache
	// raid_type
	// RaidType
	// raid_tec
	// END RIPPY DEBUGGING
	// AggregateBlockStorageHybridCacheRaidTypeRaidTec captures enum value "raid_tec"
	AggregateBlockStorageHybridCacheRaidTypeRaidTec string = "raid_tec"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStorageHybridCache
	// AggregateBlockStorageHybridCache
	// raid_type
	// RaidType
	// raid4
	// END RIPPY DEBUGGING
	// AggregateBlockStorageHybridCacheRaidTypeRaid4 captures enum value "raid4"
	AggregateBlockStorageHybridCacheRaidTypeRaid4 string = "raid4"
)

// prop value enum
func (m *AggregateBlockStorageHybridCache) validateRaidTypeEnum(path, location string, value string) error {
	if err := validate.EnumCase(path, location, value, aggregateBlockStorageHybridCacheTypeRaidTypePropEnum, true); err != nil {
		return err
	}
	return nil
}

func (m *AggregateBlockStorageHybridCache) validateRaidType(formats strfmt.Registry) error {
	if swag.IsZero(m.RaidType) { // not required
		return nil
	}

	// value enum
	if err := m.validateRaidTypeEnum("block_storage"+"."+"hybrid_cache"+"."+"raid_type", "body", m.RaidType); err != nil {
		return err
	}

	return nil
}

// ContextValidate validate this aggregate block storage hybrid cache based on the context it is used
func (m *AggregateBlockStorageHybridCache) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateDiskCount(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateEnabled(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateRaidType(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateSize(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateUsed(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateBlockStorageHybridCache) contextValidateDiskCount(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "block_storage"+"."+"hybrid_cache"+"."+"disk_count", "body", int64(m.DiskCount)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateBlockStorageHybridCache) contextValidateEnabled(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "block_storage"+"."+"hybrid_cache"+"."+"enabled", "body", m.Enabled); err != nil {
		return err
	}

	return nil
}

func (m *AggregateBlockStorageHybridCache) contextValidateRaidType(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "block_storage"+"."+"hybrid_cache"+"."+"raid_type", "body", string(m.RaidType)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateBlockStorageHybridCache) contextValidateSize(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "block_storage"+"."+"hybrid_cache"+"."+"size", "body", int64(m.Size)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateBlockStorageHybridCache) contextValidateUsed(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "block_storage"+"."+"hybrid_cache"+"."+"used", "body", int64(m.Used)); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateBlockStorageHybridCache) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateBlockStorageHybridCache) UnmarshalBinary(b []byte) error {
	var res AggregateBlockStorageHybridCache
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateBlockStorageMirror aggregate block storage mirror
//
// swagger:model AggregateBlockStorageMirror
type AggregateBlockStorageMirror struct {

	// Aggregate is SyncMirror protected
	// Example: false
	Enabled bool `json:"enabled,omitempty"`

	// state
	// Read Only: true
	// Enum: [unmirrored normal degraded resynchronizing failed]
	State string `json:"state,omitempty"`
}

// Validate validates this aggregate block storage mirror
func (m *AggregateBlockStorageMirror) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateState(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

var aggregateBlockStorageMirrorTypeStatePropEnum []interface{}

func init() {
	var res []string
	if err := json.Unmarshal([]byte(`["unmirrored","normal","degraded","resynchronizing","failed"]`), &res); err != nil {
		panic(err)
	}
	for _, v := range res {
		aggregateBlockStorageMirrorTypeStatePropEnum = append(aggregateBlockStorageMirrorTypeStatePropEnum, v)
	}
}

const (

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStorageMirror
	// AggregateBlockStorageMirror
	// state
	// State
	// unmirrored
	// END RIPPY DEBUGGING
	// AggregateBlockStorageMirrorStateUnmirrored captures enum value "unmirrored"
	AggregateBlockStorageMirrorStateUnmirrored string = "unmirrored"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStorageMirror
	// AggregateBlockStorageMirror
	// state
	// State
	// normal
	// END RIPPY DEBUGGING
	// AggregateBlockStorageMirrorStateNormal captures enum value "normal"
	AggregateBlockStorageMirrorStateNormal string = "normal"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStorageMirror
	// AggregateBlockStorageMirror
	// state
	// State
	// degraded
	// END RIPPY DEBUGGING
	// AggregateBlockStorageMirrorStateDegraded captures enum value "degraded"
	AggregateBlockStorageMirrorStateDegraded string = "degraded"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStorageMirror
	// AggregateBlockStorageMirror
	// state
	// State
	// resynchronizing
	// END RIPPY DEBUGGING
	// AggregateBlockStorageMirrorStateResynchronizing captures enum value "resynchronizing"
	AggregateBlockStorageMirrorStateResynchronizing string = "resynchronizing"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStorageMirror
	// AggregateBlockStorageMirror
	// state
	// State
	// failed
	// END RIPPY DEBUGGING
	// AggregateBlockStorageMirrorStateFailed captures enum value "failed"
	AggregateBlockStorageMirrorStateFailed string = "failed"
)

// prop value enum
func (m *AggregateBlockStorageMirror) validateStateEnum(path, location string, value string) error {
	if err := validate.EnumCase(path, location, value, aggregateBlockStorageMirrorTypeStatePropEnum, true); err != nil {
		return err
	}
	return nil
}

func (m *AggregateBlockStorageMirror) validateState(formats strfmt.Registry) error {
	if swag.IsZero(m.State) { // not required
		return nil
	}

	// value enum
	if err := m.validateStateEnum("block_storage"+"."+"mirror"+"."+"state", "body", m.State); err != nil {
		return err
	}

	return nil
}

// ContextValidate validate this aggregate block storage mirror based on the context it is used
func (m *AggregateBlockStorageMirror) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateState(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateBlockStorageMirror) contextValidateState(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "block_storage"+"."+"mirror"+"."+"state", "body", string(m.State)); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateBlockStorageMirror) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateBlockStorageMirror) UnmarshalBinary(b []byte) error {
	var res AggregateBlockStorageMirror
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateBlockStoragePrimary Configuration information for the primary storage portion of the aggregate. This excludes the hybrid cache details.
//
// swagger:model AggregateBlockStoragePrimary
type AggregateBlockStoragePrimary struct {

	// The checksum style used by the aggregate.
	// Enum: [block advanced_zoned mixed]
	ChecksumStyle string `json:"checksum_style,omitempty"`

	// The class of disks being used by the aggregate.
	// Example: performance
	// Enum: [capacity performance archive solid_state array virtual data_center capacity_flash]
	DiskClass string `json:"disk_class,omitempty"`

	// Number of disks used in the aggregate. This includes parity disks, but excludes disks in the hybrid cache.
	// Example: 8
	DiskCount int64 `json:"disk_count,omitempty"`

	// The type of disk being used by the aggregate.
	// Read Only: true
	// Enum: [fc lun nl_sas nvme_ssd sas sata scsi ssd vm_disk]
	DiskType string `json:"disk_type,omitempty"`

	// Option to specify the maximum number of disks that can be included in a RAID group.
	// Example: 16
	RaidSize int64 `json:"raid_size,omitempty"`

	// RAID type of the aggregate.
	// Enum: [raid_dp raid_tec raid0 raid4]
	RaidType string `json:"raid_type,omitempty"`
}

// Validate validates this aggregate block storage primary
func (m *AggregateBlockStoragePrimary) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateChecksumStyle(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateDiskClass(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateDiskType(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateRaidType(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

var aggregateBlockStoragePrimaryTypeChecksumStylePropEnum []interface{}

func init() {
	var res []string
	if err := json.Unmarshal([]byte(`["block","advanced_zoned","mixed"]`), &res); err != nil {
		panic(err)
	}
	for _, v := range res {
		aggregateBlockStoragePrimaryTypeChecksumStylePropEnum = append(aggregateBlockStoragePrimaryTypeChecksumStylePropEnum, v)
	}
}

const (

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// checksum_style
	// ChecksumStyle
	// block
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryChecksumStyleBlock captures enum value "block"
	AggregateBlockStoragePrimaryChecksumStyleBlock string = "block"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// checksum_style
	// ChecksumStyle
	// advanced_zoned
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryChecksumStyleAdvancedZoned captures enum value "advanced_zoned"
	AggregateBlockStoragePrimaryChecksumStyleAdvancedZoned string = "advanced_zoned"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// checksum_style
	// ChecksumStyle
	// mixed
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryChecksumStyleMixed captures enum value "mixed"
	AggregateBlockStoragePrimaryChecksumStyleMixed string = "mixed"
)

// prop value enum
func (m *AggregateBlockStoragePrimary) validateChecksumStyleEnum(path, location string, value string) error {
	if err := validate.EnumCase(path, location, value, aggregateBlockStoragePrimaryTypeChecksumStylePropEnum, true); err != nil {
		return err
	}
	return nil
}

func (m *AggregateBlockStoragePrimary) validateChecksumStyle(formats strfmt.Registry) error {
	if swag.IsZero(m.ChecksumStyle) { // not required
		return nil
	}

	// value enum
	if err := m.validateChecksumStyleEnum("block_storage"+"."+"primary"+"."+"checksum_style", "body", m.ChecksumStyle); err != nil {
		return err
	}

	return nil
}

var aggregateBlockStoragePrimaryTypeDiskClassPropEnum []interface{}

func init() {
	var res []string
	if err := json.Unmarshal([]byte(`["capacity","performance","archive","solid_state","array","virtual","data_center","capacity_flash"]`), &res); err != nil {
		panic(err)
	}
	for _, v := range res {
		aggregateBlockStoragePrimaryTypeDiskClassPropEnum = append(aggregateBlockStoragePrimaryTypeDiskClassPropEnum, v)
	}
}

const (

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_class
	// DiskClass
	// capacity
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskClassCapacity captures enum value "capacity"
	AggregateBlockStoragePrimaryDiskClassCapacity string = "capacity"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_class
	// DiskClass
	// performance
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskClassPerformance captures enum value "performance"
	AggregateBlockStoragePrimaryDiskClassPerformance string = "performance"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_class
	// DiskClass
	// archive
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskClassArchive captures enum value "archive"
	AggregateBlockStoragePrimaryDiskClassArchive string = "archive"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_class
	// DiskClass
	// solid_state
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskClassSolidState captures enum value "solid_state"
	AggregateBlockStoragePrimaryDiskClassSolidState string = "solid_state"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_class
	// DiskClass
	// array
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskClassArray captures enum value "array"
	AggregateBlockStoragePrimaryDiskClassArray string = "array"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_class
	// DiskClass
	// virtual
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskClassVirtual captures enum value "virtual"
	AggregateBlockStoragePrimaryDiskClassVirtual string = "virtual"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_class
	// DiskClass
	// data_center
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskClassDataCenter captures enum value "data_center"
	AggregateBlockStoragePrimaryDiskClassDataCenter string = "data_center"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_class
	// DiskClass
	// capacity_flash
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskClassCapacityFlash captures enum value "capacity_flash"
	AggregateBlockStoragePrimaryDiskClassCapacityFlash string = "capacity_flash"
)

// prop value enum
func (m *AggregateBlockStoragePrimary) validateDiskClassEnum(path, location string, value string) error {
	if err := validate.EnumCase(path, location, value, aggregateBlockStoragePrimaryTypeDiskClassPropEnum, true); err != nil {
		return err
	}
	return nil
}

func (m *AggregateBlockStoragePrimary) validateDiskClass(formats strfmt.Registry) error {
	if swag.IsZero(m.DiskClass) { // not required
		return nil
	}

	// value enum
	if err := m.validateDiskClassEnum("block_storage"+"."+"primary"+"."+"disk_class", "body", m.DiskClass); err != nil {
		return err
	}

	return nil
}

var aggregateBlockStoragePrimaryTypeDiskTypePropEnum []interface{}

func init() {
	var res []string
	if err := json.Unmarshal([]byte(`["fc","lun","nl_sas","nvme_ssd","sas","sata","scsi","ssd","vm_disk"]`), &res); err != nil {
		panic(err)
	}
	for _, v := range res {
		aggregateBlockStoragePrimaryTypeDiskTypePropEnum = append(aggregateBlockStoragePrimaryTypeDiskTypePropEnum, v)
	}
}

const (

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_type
	// DiskType
	// fc
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskTypeFc captures enum value "fc"
	AggregateBlockStoragePrimaryDiskTypeFc string = "fc"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_type
	// DiskType
	// lun
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskTypeLun captures enum value "lun"
	AggregateBlockStoragePrimaryDiskTypeLun string = "lun"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_type
	// DiskType
	// nl_sas
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskTypeNlSas captures enum value "nl_sas"
	AggregateBlockStoragePrimaryDiskTypeNlSas string = "nl_sas"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_type
	// DiskType
	// nvme_ssd
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskTypeNvmeSsd captures enum value "nvme_ssd"
	AggregateBlockStoragePrimaryDiskTypeNvmeSsd string = "nvme_ssd"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_type
	// DiskType
	// sas
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskTypeSas captures enum value "sas"
	AggregateBlockStoragePrimaryDiskTypeSas string = "sas"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_type
	// DiskType
	// sata
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskTypeSata captures enum value "sata"
	AggregateBlockStoragePrimaryDiskTypeSata string = "sata"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_type
	// DiskType
	// scsi
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskTypeScsi captures enum value "scsi"
	AggregateBlockStoragePrimaryDiskTypeScsi string = "scsi"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_type
	// DiskType
	// ssd
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskTypeSsd captures enum value "ssd"
	AggregateBlockStoragePrimaryDiskTypeSsd string = "ssd"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// disk_type
	// DiskType
	// vm_disk
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryDiskTypeVMDisk captures enum value "vm_disk"
	AggregateBlockStoragePrimaryDiskTypeVMDisk string = "vm_disk"
)

// prop value enum
func (m *AggregateBlockStoragePrimary) validateDiskTypeEnum(path, location string, value string) error {
	if err := validate.EnumCase(path, location, value, aggregateBlockStoragePrimaryTypeDiskTypePropEnum, true); err != nil {
		return err
	}
	return nil
}

func (m *AggregateBlockStoragePrimary) validateDiskType(formats strfmt.Registry) error {
	if swag.IsZero(m.DiskType) { // not required
		return nil
	}

	// value enum
	if err := m.validateDiskTypeEnum("block_storage"+"."+"primary"+"."+"disk_type", "body", m.DiskType); err != nil {
		return err
	}

	return nil
}

var aggregateBlockStoragePrimaryTypeRaidTypePropEnum []interface{}

func init() {
	var res []string
	if err := json.Unmarshal([]byte(`["raid_dp","raid_tec","raid0","raid4"]`), &res); err != nil {
		panic(err)
	}
	for _, v := range res {
		aggregateBlockStoragePrimaryTypeRaidTypePropEnum = append(aggregateBlockStoragePrimaryTypeRaidTypePropEnum, v)
	}
}

const (

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// raid_type
	// RaidType
	// raid_dp
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryRaidTypeRaidDp captures enum value "raid_dp"
	AggregateBlockStoragePrimaryRaidTypeRaidDp string = "raid_dp"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// raid_type
	// RaidType
	// raid_tec
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryRaidTypeRaidTec captures enum value "raid_tec"
	AggregateBlockStoragePrimaryRaidTypeRaidTec string = "raid_tec"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// raid_type
	// RaidType
	// raid0
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryRaidTypeRaid0 captures enum value "raid0"
	AggregateBlockStoragePrimaryRaidTypeRaid0 string = "raid0"

	// BEGIN RIPPY DEBUGGING
	// AggregateBlockStoragePrimary
	// AggregateBlockStoragePrimary
	// raid_type
	// RaidType
	// raid4
	// END RIPPY DEBUGGING
	// AggregateBlockStoragePrimaryRaidTypeRaid4 captures enum value "raid4"
	AggregateBlockStoragePrimaryRaidTypeRaid4 string = "raid4"
)

// prop value enum
func (m *AggregateBlockStoragePrimary) validateRaidTypeEnum(path, location string, value string) error {
	if err := validate.EnumCase(path, location, value, aggregateBlockStoragePrimaryTypeRaidTypePropEnum, true); err != nil {
		return err
	}
	return nil
}

func (m *AggregateBlockStoragePrimary) validateRaidType(formats strfmt.Registry) error {
	if swag.IsZero(m.RaidType) { // not required
		return nil
	}

	// value enum
	if err := m.validateRaidTypeEnum("block_storage"+"."+"primary"+"."+"raid_type", "body", m.RaidType); err != nil {
		return err
	}

	return nil
}

// ContextValidate validate this aggregate block storage primary based on the context it is used
func (m *AggregateBlockStoragePrimary) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateDiskType(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateBlockStoragePrimary) contextValidateDiskType(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "block_storage"+"."+"primary"+"."+"disk_type", "body", string(m.DiskType)); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateBlockStoragePrimary) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateBlockStoragePrimary) UnmarshalBinary(b []byte) error {
	var res AggregateBlockStoragePrimary
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateCloudStorage Configuration information for the cloud storage portion of the aggregate. This is referred to as the capacity tier.
//
// swagger:model AggregateCloudStorage
type AggregateCloudStorage struct {

	// Aggregate is eligible for a cloud store to be attached.
	// Read Only: true
	AttachEligible *bool `json:"attach_eligible,omitempty"`

	// Configuration information for each cloud storage portion of the aggregate.
	// Read Only: true
	Stores []*CloudStorageTier `json:"stores,omitempty"`

	// The percentage of space in the performance tier that must be used before data is tiered out to the cloud store. Only valid for PATCH operations.
	TieringFullnessThreshold int64 `json:"tiering_fullness_threshold,omitempty"`
}

// Validate validates this aggregate cloud storage
func (m *AggregateCloudStorage) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateStores(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateCloudStorage) validateStores(formats strfmt.Registry) error {
	if swag.IsZero(m.Stores) { // not required
		return nil
	}

	for i := 0; i < len(m.Stores); i++ {
		if swag.IsZero(m.Stores[i]) { // not required
			continue
		}

		if m.Stores[i] != nil {
			if err := m.Stores[i].Validate(formats); err != nil {
				if ve, ok := err.(*errors.Validation); ok {
					return ve.ValidateName("cloud_storage" + "." + "stores" + "." + strconv.Itoa(i))
				}
				return err
			}
		}

	}

	return nil
}

// ContextValidate validate this aggregate cloud storage based on the context it is used
func (m *AggregateCloudStorage) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateAttachEligible(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateStores(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateCloudStorage) contextValidateAttachEligible(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "cloud_storage"+"."+"attach_eligible", "body", m.AttachEligible); err != nil {
		return err
	}

	return nil
}

func (m *AggregateCloudStorage) contextValidateStores(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "cloud_storage"+"."+"stores", "body", []*CloudStorageTier(m.Stores)); err != nil {
		return err
	}

	for i := 0; i < len(m.Stores); i++ {

		if m.Stores[i] != nil {
			if err := m.Stores[i].ContextValidate(ctx, formats); err != nil {
				if ve, ok := err.(*errors.Validation); ok {
					return ve.ValidateName("cloud_storage" + "." + "stores" + "." + strconv.Itoa(i))
				}
				return err
			}
		}

	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateCloudStorage) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateCloudStorage) UnmarshalBinary(b []byte) error {
	var res AggregateCloudStorage
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateDataEncryption aggregate data encryption
//
// swagger:model AggregateDataEncryption
type AggregateDataEncryption struct {

	// Aggregate uses self-encrypting drives with data protection enabled.
	// Read Only: true
	DriveProtectionEnabled *bool `json:"drive_protection_enabled,omitempty"`

	// NetApp Aggregate Encryption enabled. All data in the aggregate is encrypted.
	// Read Only: true
	SoftwareEncryptionEnabled *bool `json:"software_encryption_enabled,omitempty"`
}

// Validate validates this aggregate data encryption
func (m *AggregateDataEncryption) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this aggregate data encryption based on the context it is used
func (m *AggregateDataEncryption) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateDriveProtectionEnabled(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateSoftwareEncryptionEnabled(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateDataEncryption) contextValidateDriveProtectionEnabled(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "data_encryption"+"."+"drive_protection_enabled", "body", m.DriveProtectionEnabled); err != nil {
		return err
	}

	return nil
}

func (m *AggregateDataEncryption) contextValidateSoftwareEncryptionEnabled(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "data_encryption"+"."+"software_encryption_enabled", "body", m.SoftwareEncryptionEnabled); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateDataEncryption) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateDataEncryption) UnmarshalBinary(b []byte) error {
	var res AggregateDataEncryption
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateDrHomeNode Node where the aggregate belongs after disaster recovery. The value for this field might differ from the 'node' field during switchover.
//
// swagger:model AggregateDrHomeNode
type AggregateDrHomeNode struct {

	// name
	// Example: node1
	Name string `json:"name,omitempty"`

	// uuid
	// Example: 1cd8a442-86d1-11e0-ae1c-123478563412
	UUID string `json:"uuid,omitempty"`
}

// Validate validates this aggregate dr home node
func (m *AggregateDrHomeNode) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this aggregate dr home node based on the context it is used
func (m *AggregateDrHomeNode) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

// MarshalBinary interface implementation
func (m *AggregateDrHomeNode) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateDrHomeNode) UnmarshalBinary(b []byte) error {
	var res AggregateDrHomeNode
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateHomeNode Node where the aggregate belongs after giveback. The value for this field might differ from the value of the 'node' field during takeover.
//
// swagger:model AggregateHomeNode
type AggregateHomeNode struct {

	// links
	Links *AggregateHomeNodeLinks `json:"_links,omitempty"`

	// name
	// Example: node1
	Name string `json:"name,omitempty"`

	// uuid
	// Example: 1cd8a442-86d1-11e0-ae1c-123478563412
	UUID string `json:"uuid,omitempty"`
}

// Validate validates this aggregate home node
func (m *AggregateHomeNode) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateLinks(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateHomeNode) validateLinks(formats strfmt.Registry) error {
	if swag.IsZero(m.Links) { // not required
		return nil
	}

	if m.Links != nil {
		if err := m.Links.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("home_node" + "." + "_links")
			}
			return err
		}
	}

	return nil
}

// ContextValidate validate this aggregate home node based on the context it is used
func (m *AggregateHomeNode) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateLinks(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateHomeNode) contextValidateLinks(ctx context.Context, formats strfmt.Registry) error {

	if m.Links != nil {
		if err := m.Links.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("home_node" + "." + "_links")
			}
			return err
		}
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateHomeNode) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateHomeNode) UnmarshalBinary(b []byte) error {
	var res AggregateHomeNode
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateHomeNodeLinks aggregate home node links
//
// swagger:model AggregateHomeNodeLinks
type AggregateHomeNodeLinks struct {

	// self
	Self *Href `json:"self,omitempty"`
}

// Validate validates this aggregate home node links
func (m *AggregateHomeNodeLinks) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateSelf(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateHomeNodeLinks) validateSelf(formats strfmt.Registry) error {
	if swag.IsZero(m.Self) { // not required
		return nil
	}

	if m.Self != nil {
		if err := m.Self.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("home_node" + "." + "_links" + "." + "self")
			}
			return err
		}
	}

	return nil
}

// ContextValidate validate this aggregate home node links based on the context it is used
func (m *AggregateHomeNodeLinks) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateSelf(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateHomeNodeLinks) contextValidateSelf(ctx context.Context, formats strfmt.Registry) error {

	if m.Self != nil {
		if err := m.Self.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("home_node" + "." + "_links" + "." + "self")
			}
			return err
		}
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateHomeNodeLinks) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateHomeNodeLinks) UnmarshalBinary(b []byte) error {
	var res AggregateHomeNodeLinks
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateLinks aggregate links
//
// swagger:model AggregateLinks
type AggregateLinks struct {

	// self
	Self *Href `json:"self,omitempty"`
}

// Validate validates this aggregate links
func (m *AggregateLinks) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateSelf(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateLinks) validateSelf(formats strfmt.Registry) error {
	if swag.IsZero(m.Self) { // not required
		return nil
	}

	if m.Self != nil {
		if err := m.Self.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("_links" + "." + "self")
			}
			return err
		}
	}

	return nil
}

// ContextValidate validate this aggregate links based on the context it is used
func (m *AggregateLinks) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateSelf(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateLinks) contextValidateSelf(ctx context.Context, formats strfmt.Registry) error {

	if m.Self != nil {
		if err := m.Self.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("_links" + "." + "self")
			}
			return err
		}
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateLinks) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateLinks) UnmarshalBinary(b []byte) error {
	var res AggregateLinks
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateMetric The most recent sample of I/O metrics for the aggregate.
//
// swagger:model AggregateMetric
type AggregateMetric struct {

	// links
	Links *AggregateMetricLinks `json:"_links,omitempty"`

	// The duration over which this sample is calculated. The time durations are represented in the ISO-8601 standard format. Samples can be calculated over the following durations:
	//
	// Example: PT15S
	// Read Only: true
	// Enum: [PT15S PT4M PT30M PT2H P1D PT5M]
	Duration string `json:"duration,omitempty"`

	// iops
	Iops *AggregateMetricIops `json:"iops,omitempty"`

	// latency
	Latency *AggregateMetricLatency `json:"latency,omitempty"`

	// Errors associated with the sample. For example, if the aggregation of data over multiple nodes fails, then any partial errors might return "ok" on success or "error" on an internal uncategorized failure. Whenever a sample collection is missed but done at a later time, it is back filled to the previous 15 second timestamp and tagged with "backfilled_data". "Inconsistent_ delta_time" is encountered when the time between two collections is not the same for all nodes. Therefore, the aggregated value might be over or under inflated. "Negative_delta" is returned when an expected monotonically increasing value has decreased in value. "Inconsistent_old_data" is returned when one or more nodes do not have the latest data.
	// Example: ok
	// Read Only: true
	// Enum: [ok error partial_no_data partial_no_uuid partial_no_response partial_other_error negative_delta backfilled_data inconsistent_delta_time inconsistent_old_data]
	Status string `json:"status,omitempty"`

	// throughput
	Throughput *AggregateMetricThroughput `json:"throughput,omitempty"`

	// The timestamp of the performance data.
	// Example: 2017-01-25 11:20:13
	// Read Only: true
	// Format: date-time
	Timestamp *strfmt.DateTime `json:"timestamp,omitempty"`
}

// Validate validates this aggregate metric
func (m *AggregateMetric) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateLinks(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateDuration(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateIops(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateLatency(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateStatus(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateThroughput(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateTimestamp(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateMetric) validateLinks(formats strfmt.Registry) error {
	if swag.IsZero(m.Links) { // not required
		return nil
	}

	if m.Links != nil {
		if err := m.Links.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("metric" + "." + "_links")
			}
			return err
		}
	}

	return nil
}

var aggregateMetricTypeDurationPropEnum []interface{}

func init() {
	var res []string
	if err := json.Unmarshal([]byte(`["PT15S","PT4M","PT30M","PT2H","P1D","PT5M"]`), &res); err != nil {
		panic(err)
	}
	for _, v := range res {
		aggregateMetricTypeDurationPropEnum = append(aggregateMetricTypeDurationPropEnum, v)
	}
}

const (

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// duration
	// Duration
	// PT15S
	// END RIPPY DEBUGGING
	// AggregateMetricDurationPT15S captures enum value "PT15S"
	AggregateMetricDurationPT15S string = "PT15S"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// duration
	// Duration
	// PT4M
	// END RIPPY DEBUGGING
	// AggregateMetricDurationPT4M captures enum value "PT4M"
	AggregateMetricDurationPT4M string = "PT4M"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// duration
	// Duration
	// PT30M
	// END RIPPY DEBUGGING
	// AggregateMetricDurationPT30M captures enum value "PT30M"
	AggregateMetricDurationPT30M string = "PT30M"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// duration
	// Duration
	// PT2H
	// END RIPPY DEBUGGING
	// AggregateMetricDurationPT2H captures enum value "PT2H"
	AggregateMetricDurationPT2H string = "PT2H"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// duration
	// Duration
	// P1D
	// END RIPPY DEBUGGING
	// AggregateMetricDurationP1D captures enum value "P1D"
	AggregateMetricDurationP1D string = "P1D"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// duration
	// Duration
	// PT5M
	// END RIPPY DEBUGGING
	// AggregateMetricDurationPT5M captures enum value "PT5M"
	AggregateMetricDurationPT5M string = "PT5M"
)

// prop value enum
func (m *AggregateMetric) validateDurationEnum(path, location string, value string) error {
	if err := validate.EnumCase(path, location, value, aggregateMetricTypeDurationPropEnum, true); err != nil {
		return err
	}
	return nil
}

func (m *AggregateMetric) validateDuration(formats strfmt.Registry) error {
	if swag.IsZero(m.Duration) { // not required
		return nil
	}

	// value enum
	if err := m.validateDurationEnum("metric"+"."+"duration", "body", m.Duration); err != nil {
		return err
	}

	return nil
}

func (m *AggregateMetric) validateIops(formats strfmt.Registry) error {
	if swag.IsZero(m.Iops) { // not required
		return nil
	}

	if m.Iops != nil {
		if err := m.Iops.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("metric" + "." + "iops")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateMetric) validateLatency(formats strfmt.Registry) error {
	if swag.IsZero(m.Latency) { // not required
		return nil
	}

	if m.Latency != nil {
		if err := m.Latency.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("metric" + "." + "latency")
			}
			return err
		}
	}

	return nil
}

var aggregateMetricTypeStatusPropEnum []interface{}

func init() {
	var res []string
	if err := json.Unmarshal([]byte(`["ok","error","partial_no_data","partial_no_uuid","partial_no_response","partial_other_error","negative_delta","backfilled_data","inconsistent_delta_time","inconsistent_old_data"]`), &res); err != nil {
		panic(err)
	}
	for _, v := range res {
		aggregateMetricTypeStatusPropEnum = append(aggregateMetricTypeStatusPropEnum, v)
	}
}

const (

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// status
	// Status
	// ok
	// END RIPPY DEBUGGING
	// AggregateMetricStatusOk captures enum value "ok"
	AggregateMetricStatusOk string = "ok"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// status
	// Status
	// error
	// END RIPPY DEBUGGING
	// AggregateMetricStatusError captures enum value "error"
	AggregateMetricStatusError string = "error"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// status
	// Status
	// partial_no_data
	// END RIPPY DEBUGGING
	// AggregateMetricStatusPartialNoData captures enum value "partial_no_data"
	AggregateMetricStatusPartialNoData string = "partial_no_data"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// status
	// Status
	// partial_no_uuid
	// END RIPPY DEBUGGING
	// AggregateMetricStatusPartialNoUUID captures enum value "partial_no_uuid"
	AggregateMetricStatusPartialNoUUID string = "partial_no_uuid"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// status
	// Status
	// partial_no_response
	// END RIPPY DEBUGGING
	// AggregateMetricStatusPartialNoResponse captures enum value "partial_no_response"
	AggregateMetricStatusPartialNoResponse string = "partial_no_response"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// status
	// Status
	// partial_other_error
	// END RIPPY DEBUGGING
	// AggregateMetricStatusPartialOtherError captures enum value "partial_other_error"
	AggregateMetricStatusPartialOtherError string = "partial_other_error"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// status
	// Status
	// negative_delta
	// END RIPPY DEBUGGING
	// AggregateMetricStatusNegativeDelta captures enum value "negative_delta"
	AggregateMetricStatusNegativeDelta string = "negative_delta"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// status
	// Status
	// backfilled_data
	// END RIPPY DEBUGGING
	// AggregateMetricStatusBackfilledData captures enum value "backfilled_data"
	AggregateMetricStatusBackfilledData string = "backfilled_data"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// status
	// Status
	// inconsistent_delta_time
	// END RIPPY DEBUGGING
	// AggregateMetricStatusInconsistentDeltaTime captures enum value "inconsistent_delta_time"
	AggregateMetricStatusInconsistentDeltaTime string = "inconsistent_delta_time"

	// BEGIN RIPPY DEBUGGING
	// AggregateMetric
	// AggregateMetric
	// status
	// Status
	// inconsistent_old_data
	// END RIPPY DEBUGGING
	// AggregateMetricStatusInconsistentOldData captures enum value "inconsistent_old_data"
	AggregateMetricStatusInconsistentOldData string = "inconsistent_old_data"
)

// prop value enum
func (m *AggregateMetric) validateStatusEnum(path, location string, value string) error {
	if err := validate.EnumCase(path, location, value, aggregateMetricTypeStatusPropEnum, true); err != nil {
		return err
	}
	return nil
}

func (m *AggregateMetric) validateStatus(formats strfmt.Registry) error {
	if swag.IsZero(m.Status) { // not required
		return nil
	}

	// value enum
	if err := m.validateStatusEnum("metric"+"."+"status", "body", m.Status); err != nil {
		return err
	}

	return nil
}

func (m *AggregateMetric) validateThroughput(formats strfmt.Registry) error {
	if swag.IsZero(m.Throughput) { // not required
		return nil
	}

	if m.Throughput != nil {
		if err := m.Throughput.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("metric" + "." + "throughput")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateMetric) validateTimestamp(formats strfmt.Registry) error {
	if swag.IsZero(m.Timestamp) { // not required
		return nil
	}

	if err := validate.FormatOf("metric"+"."+"timestamp", "body", "date-time", m.Timestamp.String(), formats); err != nil {
		return err
	}

	return nil
}

// ContextValidate validate this aggregate metric based on the context it is used
func (m *AggregateMetric) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateLinks(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateDuration(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateIops(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateLatency(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateStatus(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateThroughput(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateTimestamp(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateMetric) contextValidateLinks(ctx context.Context, formats strfmt.Registry) error {

	if m.Links != nil {
		if err := m.Links.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("metric" + "." + "_links")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateMetric) contextValidateDuration(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "metric"+"."+"duration", "body", string(m.Duration)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateMetric) contextValidateIops(ctx context.Context, formats strfmt.Registry) error {

	if m.Iops != nil {
		if err := m.Iops.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("metric" + "." + "iops")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateMetric) contextValidateLatency(ctx context.Context, formats strfmt.Registry) error {

	if m.Latency != nil {
		if err := m.Latency.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("metric" + "." + "latency")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateMetric) contextValidateStatus(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "metric"+"."+"status", "body", string(m.Status)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateMetric) contextValidateThroughput(ctx context.Context, formats strfmt.Registry) error {

	if m.Throughput != nil {
		if err := m.Throughput.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("metric" + "." + "throughput")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateMetric) contextValidateTimestamp(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "metric"+"."+"timestamp", "body", m.Timestamp); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateMetric) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateMetric) UnmarshalBinary(b []byte) error {
	var res AggregateMetric
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateMetricIops The rate of I/O operations observed at the storage object.
//
// swagger:model AggregateMetricIops
type AggregateMetricIops struct {

	// Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.
	Other int64 `json:"other,omitempty"`

	// Performance metric for read I/O operations.
	// Example: 200
	Read int64 `json:"read,omitempty"`

	// Performance metric aggregated over all types of I/O operations.
	// Example: 1000
	Total int64 `json:"total,omitempty"`

	// Peformance metric for write I/O operations.
	// Example: 100
	Write int64 `json:"write,omitempty"`
}

// Validate validates this aggregate metric iops
func (m *AggregateMetricIops) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this aggregate metric iops based on the context it is used
func (m *AggregateMetricIops) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

// MarshalBinary interface implementation
func (m *AggregateMetricIops) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateMetricIops) UnmarshalBinary(b []byte) error {
	var res AggregateMetricIops
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateMetricLatency The round trip latency in microseconds observed at the storage object.
//
// swagger:model AggregateMetricLatency
type AggregateMetricLatency struct {

	// Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.
	Other int64 `json:"other,omitempty"`

	// Performance metric for read I/O operations.
	// Example: 200
	Read int64 `json:"read,omitempty"`

	// Performance metric aggregated over all types of I/O operations.
	// Example: 1000
	Total int64 `json:"total,omitempty"`

	// Peformance metric for write I/O operations.
	// Example: 100
	Write int64 `json:"write,omitempty"`
}

// Validate validates this aggregate metric latency
func (m *AggregateMetricLatency) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this aggregate metric latency based on the context it is used
func (m *AggregateMetricLatency) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

// MarshalBinary interface implementation
func (m *AggregateMetricLatency) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateMetricLatency) UnmarshalBinary(b []byte) error {
	var res AggregateMetricLatency
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateMetricLinks aggregate metric links
//
// swagger:model AggregateMetricLinks
type AggregateMetricLinks struct {

	// self
	Self *Href `json:"self,omitempty"`
}

// Validate validates this aggregate metric links
func (m *AggregateMetricLinks) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateSelf(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateMetricLinks) validateSelf(formats strfmt.Registry) error {
	if swag.IsZero(m.Self) { // not required
		return nil
	}

	if m.Self != nil {
		if err := m.Self.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("metric" + "." + "_links" + "." + "self")
			}
			return err
		}
	}

	return nil
}

// ContextValidate validate this aggregate metric links based on the context it is used
func (m *AggregateMetricLinks) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateSelf(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateMetricLinks) contextValidateSelf(ctx context.Context, formats strfmt.Registry) error {

	if m.Self != nil {
		if err := m.Self.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("metric" + "." + "_links" + "." + "self")
			}
			return err
		}
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateMetricLinks) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateMetricLinks) UnmarshalBinary(b []byte) error {
	var res AggregateMetricLinks
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateMetricThroughput The rate of throughput bytes per second observed at the storage object.
//
// swagger:model AggregateMetricThroughput
type AggregateMetricThroughput struct {

	// Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.
	Other int64 `json:"other,omitempty"`

	// Performance metric for read I/O operations.
	// Example: 200
	Read int64 `json:"read,omitempty"`

	// Performance metric aggregated over all types of I/O operations.
	// Example: 1000
	Total int64 `json:"total,omitempty"`

	// Peformance metric for write I/O operations.
	// Example: 100
	Write int64 `json:"write,omitempty"`
}

// Validate validates this aggregate metric throughput
func (m *AggregateMetricThroughput) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this aggregate metric throughput based on the context it is used
func (m *AggregateMetricThroughput) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

// MarshalBinary interface implementation
func (m *AggregateMetricThroughput) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateMetricThroughput) UnmarshalBinary(b []byte) error {
	var res AggregateMetricThroughput
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateNode Node where the aggregate currently resides.
//
// swagger:model AggregateNode
type AggregateNode struct {

	// links
	Links *AggregateNodeLinks `json:"_links,omitempty"`

	// name
	// Example: node1
	Name string `json:"name,omitempty"`

	// uuid
	// Example: 1cd8a442-86d1-11e0-ae1c-123478563412
	UUID string `json:"uuid,omitempty"`
}

// Validate validates this aggregate node
func (m *AggregateNode) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateLinks(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateNode) validateLinks(formats strfmt.Registry) error {
	if swag.IsZero(m.Links) { // not required
		return nil
	}

	if m.Links != nil {
		if err := m.Links.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("node" + "." + "_links")
			}
			return err
		}
	}

	return nil
}

// ContextValidate validate this aggregate node based on the context it is used
func (m *AggregateNode) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateLinks(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateNode) contextValidateLinks(ctx context.Context, formats strfmt.Registry) error {

	if m.Links != nil {
		if err := m.Links.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("node" + "." + "_links")
			}
			return err
		}
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateNode) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateNode) UnmarshalBinary(b []byte) error {
	var res AggregateNode
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateNodeLinks aggregate node links
//
// swagger:model AggregateNodeLinks
type AggregateNodeLinks struct {

	// self
	Self *Href `json:"self,omitempty"`
}

// Validate validates this aggregate node links
func (m *AggregateNodeLinks) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateSelf(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateNodeLinks) validateSelf(formats strfmt.Registry) error {
	if swag.IsZero(m.Self) { // not required
		return nil
	}

	if m.Self != nil {
		if err := m.Self.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("node" + "." + "_links" + "." + "self")
			}
			return err
		}
	}

	return nil
}

// ContextValidate validate this aggregate node links based on the context it is used
func (m *AggregateNodeLinks) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateSelf(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateNodeLinks) contextValidateSelf(ctx context.Context, formats strfmt.Registry) error {

	if m.Self != nil {
		if err := m.Self.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("node" + "." + "_links" + "." + "self")
			}
			return err
		}
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateNodeLinks) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateNodeLinks) UnmarshalBinary(b []byte) error {
	var res AggregateNodeLinks
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateSpace aggregate space
//
// swagger:model AggregateSpace
type AggregateSpace struct {

	// block storage
	BlockStorage *AggregateSpaceBlockStorage `json:"block_storage,omitempty"`

	// cloud storage
	CloudStorage *AggregateSpaceCloudStorage `json:"cloud_storage,omitempty"`

	// efficiency
	Efficiency *AggregateSpaceEfficiency `json:"efficiency,omitempty"`

	// efficiency without snapshots
	EfficiencyWithoutSnapshots *AggregateSpaceEfficiencyWithoutSnapshots `json:"efficiency_without_snapshots,omitempty"`

	// A summation of volume footprints (including volume guarantees), in bytes. This includes all of the volume footprints in the block_storage tier and the cloud_storage tier.
	// This is an advanced property; there is an added cost to retrieving its value. The field is not populated for either a collection GET or an instance GET unless it is explicitly requested using the <i>fields</i> query parameter containing either footprint or **.
	//
	// Example: 608896
	// Read Only: true
	Footprint int64 `json:"footprint,omitempty"`
}

// Validate validates this aggregate space
func (m *AggregateSpace) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateBlockStorage(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateCloudStorage(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateEfficiency(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateEfficiencyWithoutSnapshots(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateSpace) validateBlockStorage(formats strfmt.Registry) error {
	if swag.IsZero(m.BlockStorage) { // not required
		return nil
	}

	if m.BlockStorage != nil {
		if err := m.BlockStorage.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("space" + "." + "block_storage")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateSpace) validateCloudStorage(formats strfmt.Registry) error {
	if swag.IsZero(m.CloudStorage) { // not required
		return nil
	}

	if m.CloudStorage != nil {
		if err := m.CloudStorage.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("space" + "." + "cloud_storage")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateSpace) validateEfficiency(formats strfmt.Registry) error {
	if swag.IsZero(m.Efficiency) { // not required
		return nil
	}

	if m.Efficiency != nil {
		if err := m.Efficiency.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("space" + "." + "efficiency")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateSpace) validateEfficiencyWithoutSnapshots(formats strfmt.Registry) error {
	if swag.IsZero(m.EfficiencyWithoutSnapshots) { // not required
		return nil
	}

	if m.EfficiencyWithoutSnapshots != nil {
		if err := m.EfficiencyWithoutSnapshots.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("space" + "." + "efficiency_without_snapshots")
			}
			return err
		}
	}

	return nil
}

// ContextValidate validate this aggregate space based on the context it is used
func (m *AggregateSpace) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateBlockStorage(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateCloudStorage(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateEfficiency(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateEfficiencyWithoutSnapshots(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateFootprint(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateSpace) contextValidateBlockStorage(ctx context.Context, formats strfmt.Registry) error {

	if m.BlockStorage != nil {
		if err := m.BlockStorage.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("space" + "." + "block_storage")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateSpace) contextValidateCloudStorage(ctx context.Context, formats strfmt.Registry) error {

	if m.CloudStorage != nil {
		if err := m.CloudStorage.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("space" + "." + "cloud_storage")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateSpace) contextValidateEfficiency(ctx context.Context, formats strfmt.Registry) error {

	if m.Efficiency != nil {
		if err := m.Efficiency.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("space" + "." + "efficiency")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateSpace) contextValidateEfficiencyWithoutSnapshots(ctx context.Context, formats strfmt.Registry) error {

	if m.EfficiencyWithoutSnapshots != nil {
		if err := m.EfficiencyWithoutSnapshots.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("space" + "." + "efficiency_without_snapshots")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateSpace) contextValidateFootprint(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "space"+"."+"footprint", "body", int64(m.Footprint)); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateSpace) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateSpace) UnmarshalBinary(b []byte) error {
	var res AggregateSpace
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateSpaceBlockStorage aggregate space block storage
//
// swagger:model AggregateSpaceBlockStorage
type AggregateSpaceBlockStorage struct {

	// Space available in bytes
	// Example: 10156560384
	// Read Only: true
	Available int64 `json:"available,omitempty"`

	// The aggregate used percentage at which 'monitor.volume.full' EMS is generated.
	// Read Only: true
	FullThresholdPercent int64 `json:"full_threshold_percent,omitempty"`

	// The size that is physically used in the block storage and has a cold temperature, in bytes. This property is only supported if the aggregate is either attached to a cloud store or can be attached to a cloud store.
	// This is an advanced property; there is an added cost to retrieving its value. The field is not populated for either a collection GET or an instance GET unless it is explicitly requested using the <i>fields</i> query parameter containing either block_storage.inactive_user_data or **.
	//
	// Example: 304448
	// Read Only: true
	InactiveUserData int64 `json:"inactive_user_data,omitempty"`

	// Total usable space in bytes, not including WAFL reserve and aggregate Snapshot copy reserve.
	// Example: 10156769280
	// Read Only: true
	Size int64 `json:"size,omitempty"`

	// Space used or reserved in bytes. Includes volume guarantees and aggregate metadata.
	// Example: 2088960
	// Read Only: true
	Used int64 `json:"used,omitempty"`
}

// Validate validates this aggregate space block storage
func (m *AggregateSpaceBlockStorage) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this aggregate space block storage based on the context it is used
func (m *AggregateSpaceBlockStorage) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateAvailable(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateFullThresholdPercent(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateInactiveUserData(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateSize(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateUsed(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateSpaceBlockStorage) contextValidateAvailable(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "space"+"."+"block_storage"+"."+"available", "body", int64(m.Available)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateSpaceBlockStorage) contextValidateFullThresholdPercent(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "space"+"."+"block_storage"+"."+"full_threshold_percent", "body", int64(m.FullThresholdPercent)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateSpaceBlockStorage) contextValidateInactiveUserData(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "space"+"."+"block_storage"+"."+"inactive_user_data", "body", int64(m.InactiveUserData)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateSpaceBlockStorage) contextValidateSize(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "space"+"."+"block_storage"+"."+"size", "body", int64(m.Size)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateSpaceBlockStorage) contextValidateUsed(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "space"+"."+"block_storage"+"."+"used", "body", int64(m.Used)); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateSpaceBlockStorage) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateSpaceBlockStorage) UnmarshalBinary(b []byte) error {
	var res AggregateSpaceBlockStorage
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateSpaceCloudStorage aggregate space cloud storage
//
// swagger:model AggregateSpaceCloudStorage
type AggregateSpaceCloudStorage struct {

	// Used space in bytes in the cloud store. Only applicable for aggregate with a cloud store tier.
	// Example: 402743264
	// Read Only: true
	Used int64 `json:"used,omitempty"`
}

// Validate validates this aggregate space cloud storage
func (m *AggregateSpaceCloudStorage) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this aggregate space cloud storage based on the context it is used
func (m *AggregateSpaceCloudStorage) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateUsed(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateSpaceCloudStorage) contextValidateUsed(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "space"+"."+"cloud_storage"+"."+"used", "body", int64(m.Used)); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateSpaceCloudStorage) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateSpaceCloudStorage) UnmarshalBinary(b []byte) error {
	var res AggregateSpaceCloudStorage
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateSpaceEfficiency Storage efficiency
//
// swagger:model AggregateSpaceEfficiency
type AggregateSpaceEfficiency struct {

	// Logical used
	// Read Only: true
	LogicalUsed int64 `json:"logical_used,omitempty"`

	// Data reduction ratio (logical_used / used)
	// Read Only: true
	Ratio float64 `json:"ratio,omitempty"`

	// Space saved by storage efficiencies (logical_used - used)
	// Read Only: true
	Savings int64 `json:"savings,omitempty"`
}

// Validate validates this aggregate space efficiency
func (m *AggregateSpaceEfficiency) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this aggregate space efficiency based on the context it is used
func (m *AggregateSpaceEfficiency) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateLogicalUsed(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateRatio(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateSavings(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateSpaceEfficiency) contextValidateLogicalUsed(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "space"+"."+"efficiency"+"."+"logical_used", "body", int64(m.LogicalUsed)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateSpaceEfficiency) contextValidateRatio(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "space"+"."+"efficiency"+"."+"ratio", "body", float64(m.Ratio)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateSpaceEfficiency) contextValidateSavings(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "space"+"."+"efficiency"+"."+"savings", "body", int64(m.Savings)); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateSpaceEfficiency) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateSpaceEfficiency) UnmarshalBinary(b []byte) error {
	var res AggregateSpaceEfficiency
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateSpaceEfficiencyWithoutSnapshots Storage efficiency that does not include the savings provided by Snapshot copies
//
// swagger:model AggregateSpaceEfficiencyWithoutSnapshots
type AggregateSpaceEfficiencyWithoutSnapshots struct {

	// Logical used
	// Read Only: true
	LogicalUsed int64 `json:"logical_used,omitempty"`

	// Data reduction ratio (logical_used / used)
	// Read Only: true
	Ratio float64 `json:"ratio,omitempty"`

	// Space saved by storage efficiencies (logical_used - used)
	// Read Only: true
	Savings int64 `json:"savings,omitempty"`
}

// Validate validates this aggregate space efficiency without snapshots
func (m *AggregateSpaceEfficiencyWithoutSnapshots) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this aggregate space efficiency without snapshots based on the context it is used
func (m *AggregateSpaceEfficiencyWithoutSnapshots) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateLogicalUsed(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateRatio(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateSavings(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateSpaceEfficiencyWithoutSnapshots) contextValidateLogicalUsed(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "space"+"."+"efficiency_without_snapshots"+"."+"logical_used", "body", int64(m.LogicalUsed)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateSpaceEfficiencyWithoutSnapshots) contextValidateRatio(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "space"+"."+"efficiency_without_snapshots"+"."+"ratio", "body", float64(m.Ratio)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateSpaceEfficiencyWithoutSnapshots) contextValidateSavings(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "space"+"."+"efficiency_without_snapshots"+"."+"savings", "body", int64(m.Savings)); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateSpaceEfficiencyWithoutSnapshots) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateSpaceEfficiencyWithoutSnapshots) UnmarshalBinary(b []byte) error {
	var res AggregateSpaceEfficiencyWithoutSnapshots
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateStatistics The real time I/O statistics for the aggregate.
//
// swagger:model AggregateStatistics
type AggregateStatistics struct {

	// iops raw
	IopsRaw *AggregateStatisticsIopsRaw `json:"iops_raw,omitempty"`

	// latency raw
	LatencyRaw *AggregateStatisticsLatencyRaw `json:"latency_raw,omitempty"`

	// Errors associated with the sample. For example, if the aggregation of data over multiple nodes fails, then any partial errors might return "ok" on success or "error" on an internal uncategorized failure. Whenever a sample collection is missed but done at a later time, it is back filled to the previous 15 second timestamp and tagged with "backfilled_data". "Inconsistent_ delta_time" is encountered when the time between two collections is not the same for all nodes. Therefore, the aggregated value might be over or under inflated. "Negative_delta" is returned when an expected monotonically increasing value has decreased in value. "Inconsistent_old_data" is returned when one or more nodes do not have the latest data.
	// Example: ok
	// Read Only: true
	// Enum: [ok error partial_no_data partial_no_uuid partial_no_response partial_other_error negative_delta backfilled_data inconsistent_delta_time inconsistent_old_data]
	Status string `json:"status,omitempty"`

	// throughput raw
	ThroughputRaw *AggregateStatisticsThroughputRaw `json:"throughput_raw,omitempty"`

	// The timestamp of the performance data.
	// Example: 2017-01-25 11:20:13
	// Read Only: true
	// Format: date-time
	Timestamp *strfmt.DateTime `json:"timestamp,omitempty"`
}

// Validate validates this aggregate statistics
func (m *AggregateStatistics) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateIopsRaw(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateLatencyRaw(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateStatus(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateThroughputRaw(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateTimestamp(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateStatistics) validateIopsRaw(formats strfmt.Registry) error {
	if swag.IsZero(m.IopsRaw) { // not required
		return nil
	}

	if m.IopsRaw != nil {
		if err := m.IopsRaw.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("statistics" + "." + "iops_raw")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateStatistics) validateLatencyRaw(formats strfmt.Registry) error {
	if swag.IsZero(m.LatencyRaw) { // not required
		return nil
	}

	if m.LatencyRaw != nil {
		if err := m.LatencyRaw.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("statistics" + "." + "latency_raw")
			}
			return err
		}
	}

	return nil
}

var aggregateStatisticsTypeStatusPropEnum []interface{}

func init() {
	var res []string
	if err := json.Unmarshal([]byte(`["ok","error","partial_no_data","partial_no_uuid","partial_no_response","partial_other_error","negative_delta","backfilled_data","inconsistent_delta_time","inconsistent_old_data"]`), &res); err != nil {
		panic(err)
	}
	for _, v := range res {
		aggregateStatisticsTypeStatusPropEnum = append(aggregateStatisticsTypeStatusPropEnum, v)
	}
}

const (

	// BEGIN RIPPY DEBUGGING
	// AggregateStatistics
	// AggregateStatistics
	// status
	// Status
	// ok
	// END RIPPY DEBUGGING
	// AggregateStatisticsStatusOk captures enum value "ok"
	AggregateStatisticsStatusOk string = "ok"

	// BEGIN RIPPY DEBUGGING
	// AggregateStatistics
	// AggregateStatistics
	// status
	// Status
	// error
	// END RIPPY DEBUGGING
	// AggregateStatisticsStatusError captures enum value "error"
	AggregateStatisticsStatusError string = "error"

	// BEGIN RIPPY DEBUGGING
	// AggregateStatistics
	// AggregateStatistics
	// status
	// Status
	// partial_no_data
	// END RIPPY DEBUGGING
	// AggregateStatisticsStatusPartialNoData captures enum value "partial_no_data"
	AggregateStatisticsStatusPartialNoData string = "partial_no_data"

	// BEGIN RIPPY DEBUGGING
	// AggregateStatistics
	// AggregateStatistics
	// status
	// Status
	// partial_no_uuid
	// END RIPPY DEBUGGING
	// AggregateStatisticsStatusPartialNoUUID captures enum value "partial_no_uuid"
	AggregateStatisticsStatusPartialNoUUID string = "partial_no_uuid"

	// BEGIN RIPPY DEBUGGING
	// AggregateStatistics
	// AggregateStatistics
	// status
	// Status
	// partial_no_response
	// END RIPPY DEBUGGING
	// AggregateStatisticsStatusPartialNoResponse captures enum value "partial_no_response"
	AggregateStatisticsStatusPartialNoResponse string = "partial_no_response"

	// BEGIN RIPPY DEBUGGING
	// AggregateStatistics
	// AggregateStatistics
	// status
	// Status
	// partial_other_error
	// END RIPPY DEBUGGING
	// AggregateStatisticsStatusPartialOtherError captures enum value "partial_other_error"
	AggregateStatisticsStatusPartialOtherError string = "partial_other_error"

	// BEGIN RIPPY DEBUGGING
	// AggregateStatistics
	// AggregateStatistics
	// status
	// Status
	// negative_delta
	// END RIPPY DEBUGGING
	// AggregateStatisticsStatusNegativeDelta captures enum value "negative_delta"
	AggregateStatisticsStatusNegativeDelta string = "negative_delta"

	// BEGIN RIPPY DEBUGGING
	// AggregateStatistics
	// AggregateStatistics
	// status
	// Status
	// backfilled_data
	// END RIPPY DEBUGGING
	// AggregateStatisticsStatusBackfilledData captures enum value "backfilled_data"
	AggregateStatisticsStatusBackfilledData string = "backfilled_data"

	// BEGIN RIPPY DEBUGGING
	// AggregateStatistics
	// AggregateStatistics
	// status
	// Status
	// inconsistent_delta_time
	// END RIPPY DEBUGGING
	// AggregateStatisticsStatusInconsistentDeltaTime captures enum value "inconsistent_delta_time"
	AggregateStatisticsStatusInconsistentDeltaTime string = "inconsistent_delta_time"

	// BEGIN RIPPY DEBUGGING
	// AggregateStatistics
	// AggregateStatistics
	// status
	// Status
	// inconsistent_old_data
	// END RIPPY DEBUGGING
	// AggregateStatisticsStatusInconsistentOldData captures enum value "inconsistent_old_data"
	AggregateStatisticsStatusInconsistentOldData string = "inconsistent_old_data"
)

// prop value enum
func (m *AggregateStatistics) validateStatusEnum(path, location string, value string) error {
	if err := validate.EnumCase(path, location, value, aggregateStatisticsTypeStatusPropEnum, true); err != nil {
		return err
	}
	return nil
}

func (m *AggregateStatistics) validateStatus(formats strfmt.Registry) error {
	if swag.IsZero(m.Status) { // not required
		return nil
	}

	// value enum
	if err := m.validateStatusEnum("statistics"+"."+"status", "body", m.Status); err != nil {
		return err
	}

	return nil
}

func (m *AggregateStatistics) validateThroughputRaw(formats strfmt.Registry) error {
	if swag.IsZero(m.ThroughputRaw) { // not required
		return nil
	}

	if m.ThroughputRaw != nil {
		if err := m.ThroughputRaw.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("statistics" + "." + "throughput_raw")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateStatistics) validateTimestamp(formats strfmt.Registry) error {
	if swag.IsZero(m.Timestamp) { // not required
		return nil
	}

	if err := validate.FormatOf("statistics"+"."+"timestamp", "body", "date-time", m.Timestamp.String(), formats); err != nil {
		return err
	}

	return nil
}

// ContextValidate validate this aggregate statistics based on the context it is used
func (m *AggregateStatistics) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if err := m.contextValidateIopsRaw(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateLatencyRaw(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateStatus(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateThroughputRaw(ctx, formats); err != nil {
		res = append(res, err)
	}

	if err := m.contextValidateTimestamp(ctx, formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *AggregateStatistics) contextValidateIopsRaw(ctx context.Context, formats strfmt.Registry) error {

	if m.IopsRaw != nil {
		if err := m.IopsRaw.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("statistics" + "." + "iops_raw")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateStatistics) contextValidateLatencyRaw(ctx context.Context, formats strfmt.Registry) error {

	if m.LatencyRaw != nil {
		if err := m.LatencyRaw.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("statistics" + "." + "latency_raw")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateStatistics) contextValidateStatus(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "statistics"+"."+"status", "body", string(m.Status)); err != nil {
		return err
	}

	return nil
}

func (m *AggregateStatistics) contextValidateThroughputRaw(ctx context.Context, formats strfmt.Registry) error {

	if m.ThroughputRaw != nil {
		if err := m.ThroughputRaw.ContextValidate(ctx, formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("statistics" + "." + "throughput_raw")
			}
			return err
		}
	}

	return nil
}

func (m *AggregateStatistics) contextValidateTimestamp(ctx context.Context, formats strfmt.Registry) error {

	if err := validate.ReadOnly(ctx, "statistics"+"."+"timestamp", "body", m.Timestamp); err != nil {
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *AggregateStatistics) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateStatistics) UnmarshalBinary(b []byte) error {
	var res AggregateStatistics
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateStatisticsIopsRaw The number of I/O operations observed at the storage object. This can be used along with delta time to calculate the rate of I/O operations per unit of time.
//
// swagger:model AggregateStatisticsIopsRaw
type AggregateStatisticsIopsRaw struct {

	// Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.
	Other int64 `json:"other,omitempty"`

	// Performance metric for read I/O operations.
	// Example: 200
	Read int64 `json:"read,omitempty"`

	// Performance metric aggregated over all types of I/O operations.
	// Example: 1000
	Total int64 `json:"total,omitempty"`

	// Peformance metric for write I/O operations.
	// Example: 100
	Write int64 `json:"write,omitempty"`
}

// Validate validates this aggregate statistics iops raw
func (m *AggregateStatisticsIopsRaw) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this aggregate statistics iops raw based on the context it is used
func (m *AggregateStatisticsIopsRaw) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

// MarshalBinary interface implementation
func (m *AggregateStatisticsIopsRaw) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateStatisticsIopsRaw) UnmarshalBinary(b []byte) error {
	var res AggregateStatisticsIopsRaw
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateStatisticsLatencyRaw The raw latency in microseconds observed at the storage object. This can be divided by the raw IOPS value to calculate the average latency per I/O operation.
//
// swagger:model AggregateStatisticsLatencyRaw
type AggregateStatisticsLatencyRaw struct {

	// Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.
	Other int64 `json:"other,omitempty"`

	// Performance metric for read I/O operations.
	// Example: 200
	Read int64 `json:"read,omitempty"`

	// Performance metric aggregated over all types of I/O operations.
	// Example: 1000
	Total int64 `json:"total,omitempty"`

	// Peformance metric for write I/O operations.
	// Example: 100
	Write int64 `json:"write,omitempty"`
}

// Validate validates this aggregate statistics latency raw
func (m *AggregateStatisticsLatencyRaw) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this aggregate statistics latency raw based on the context it is used
func (m *AggregateStatisticsLatencyRaw) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

// MarshalBinary interface implementation
func (m *AggregateStatisticsLatencyRaw) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateStatisticsLatencyRaw) UnmarshalBinary(b []byte) error {
	var res AggregateStatisticsLatencyRaw
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// AggregateStatisticsThroughputRaw Throughput bytes observed at the storage object. This can be used along with delta time to calculate the rate of throughput bytes per unit of time.
//
// swagger:model AggregateStatisticsThroughputRaw
type AggregateStatisticsThroughputRaw struct {

	// Performance metric for other I/O operations. Other I/O operations can be metadata operations, such as directory lookups and so on.
	Other int64 `json:"other,omitempty"`

	// Performance metric for read I/O operations.
	// Example: 200
	Read int64 `json:"read,omitempty"`

	// Performance metric aggregated over all types of I/O operations.
	// Example: 1000
	Total int64 `json:"total,omitempty"`

	// Peformance metric for write I/O operations.
	// Example: 100
	Write int64 `json:"write,omitempty"`
}

// Validate validates this aggregate statistics throughput raw
func (m *AggregateStatisticsThroughputRaw) Validate(formats strfmt.Registry) error {
	return nil
}

// ContextValidate validate this aggregate statistics throughput raw based on the context it is used
func (m *AggregateStatisticsThroughputRaw) ContextValidate(ctx context.Context, formats strfmt.Registry) error {
	var res []error

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

// MarshalBinary interface implementation
func (m *AggregateStatisticsThroughputRaw) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *AggregateStatisticsThroughputRaw) UnmarshalBinary(b []byte) error {
	var res AggregateStatisticsThroughputRaw
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}

// HELLO RIPPY
